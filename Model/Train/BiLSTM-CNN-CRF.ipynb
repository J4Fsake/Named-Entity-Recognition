{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNZHf1pq-d3H"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "The paper uses the Vietnamese data, which is present in the \"data\" directory of this project. We will later apply more preprocessing steps to generate tag mapping, word mapping and character  mapping. The data set contains 10 different types of named entities: PATIENT_ID, PERSON_NAME, AGE, GENDER, OCCUPATION, LOCATION, ORGANIZATION, SYMPTOM & DISEASE, TRANSPORTATION and DATE. Regarding the tagging scheme, we will use BIOES (the same with the one in the research paper); however, in order to serve the task of model evaluation and error extract we will use the BIO2 tagging scheme\n",
        "\n",
        "BIOES tagging Scheme:\n",
        "\n",
        "    B-X - Beginning of chunk X\n",
        "    I-X - Inside of chunk X (not first or last)\n",
        "    E-X - End of chunk X\n",
        "    S-X - Single-token chunk X\n",
        "    O - Outside of any chunk\n",
        "  \n",
        "BIO2 tagging scheme:\n",
        "    B-X - Beginning of chunk X (can be first or last)\n",
        "    I-X - Inside of chunk X (not first but can be last)\n",
        "    O - Outside of any chunk\n",
        "\n",
        "Example of Vietnamese-NER sentence available in the data:\n",
        "    \n",
        "    Đồng_thời O\n",
        "    , O\n",
        "    bệnh_viện O\n",
        "    tiếp_tục O\n",
        "    thực_hiện O\n",
        "    các O\n",
        "    biện_pháp O\n",
        "    phòng_chống O\n",
        "    dịch_bệnh O\n",
        "    COVID O\n",
        "    - O\n",
        "    19 O\n",
        "    theo O\n",
        "    hướng_dẫn O\n",
        "    của O\n",
        "    Bộ B-ORGANIZATION\n",
        "    Y_tế I-ORGANIZATION\n",
        "    . O\n",
        "    \n",
        "Data Split(We use the same split as mentioned in paper, with the ratio of 50%, 20% and 30% for train, validation and test data, repesctively).:\n",
        "\n",
        "    Training Data - train_word.conll\n",
        "    Validation Data - dev_word.conll\n",
        "    Testing Data - test_word.conll\n",
        "\n",
        "Note: For the LSTM-CNN-CRF model we will use word data but not the syllable one. For example:\n",
        "    \n",
        "  Word data: The word \"bệnh viện\" will be considered as a single word those 2 words, \"bệnh\" and \"viện\", will be concatenated by an underscore: \"bệnh viện\" -> \"bệnh_viện\"\n",
        "\n",
        "  Syllable data: The word \"bệnh viện\" will be considered as two separated words: \"bệnh viện\" -> \"bệnh\", \"viện\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG73LpuI_9SA",
        "outputId": "a21b920b-1ea5-4064-c828-9aabea4f27bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  4 09:47:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i00hiG1uwNnK",
        "outputId": "81fb0c88-42de-4bd0-b52a-80bca52267aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkBK6MD5BCBA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content/drive/MyDrive/NLP project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjqfst3Uxh7O",
        "outputId": "9c3a44d0-ad8b-45fc-b658-c7a8e1fd1fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=444691acc1771735aa6344b3f66721aeb7e3070415ee129322ce8cd359880c22\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn\n",
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_UKqys1-d3I"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "from torch import autograd\n",
        "\n",
        "import time\n",
        "import _pickle as cPickle\n",
        "\n",
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "# import seaborn\n",
        "# plt.rcParams['figure.dpi'] = 80\n",
        "# plt.style.use('seaborn-pastel')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGKTCS4P-d3K"
      },
      "source": [
        "## Define constants and paramaters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxPPDkFN-d3K"
      },
      "source": [
        "We now define some constants and parameters that we will be using later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBrGkqFz-d3L"
      },
      "outputs": [],
      "source": [
        "parameters = OrderedDict()\n",
        "parameters['train'] = './PhoNER_COVID19/data/word/train_word.conll' #Path to train file\n",
        "parameters['dev'] = './PhoNER_COVID19/data/word/dev_word.conll' #Path to test file\n",
        "parameters['test'] = './PhoNER_COVID19/data/word/test_word.conll' #Path to dev file\n",
        "parameters['tag_scheme'] = \"BIO\" #BIO or BIOES\n",
        "parameters['lower'] = True # Boolean variable to control lowercasing of words\n",
        "parameters['zeros'] =  False # Chỉnh\n",
        "parameters['char_dim'] = 100 #Char embedding dimension\n",
        "parameters['word_dim'] = 300 #Token embedding dimension\n",
        "parameters['word_lstm_dim'] = 200 #Chỉnh\n",
        "parameters['word_bidirect'] = True #Use a bidirectional LSTM for words\n",
        "parameters['embedding_path'] = \"./PhoW2V/word2vec_vi_words_300dims.txt\" #Location of pretrained embeddings\n",
        "parameters['all_emb'] = 1 #Load all embeddings\n",
        "parameters['crf'] =1 #Use CRF (0 to disable)\n",
        "parameters['dropout'] = 0.75\n",
        "parameters['epoch'] =  30 # giống trong paper\n",
        "parameters['weights'] = \"./End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/models/self-trained-model-1\" #path to Pretrained for from a previous run\n",
        "# parameters['name'] = \"self-trained-model\" # Model name\n",
        "parameters['name'] = \"model_word_version\" # Model name\n",
        "parameters['gradient_clip']=5.0\n",
        "parameters['char_mode']=\"CNN\"\n",
        "models_path = \"./End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/models/\" #path to saved models\n",
        "\n",
        "#GPU\n",
        "parameters['use_gpu'] = torch.cuda.is_available() #GPU Check\n",
        "use_gpu = parameters['use_gpu']\n",
        "\n",
        "parameters['reload'] = False\n",
        "\n",
        "#Constants\n",
        "START_TAG = '<START>'\n",
        "STOP_TAG = '<STOP>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhuFyTvI-d3M"
      },
      "outputs": [],
      "source": [
        "#paths to files\n",
        "#To stored mapping file\n",
        "mapping_file = './End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/data/mapping.pkl'\n",
        "\n",
        "#To stored model\n",
        "name = parameters['name']\n",
        "model_name = models_path + name #get_name(parameters)\n",
        "\n",
        "if not os.path.exists(models_path):\n",
        "    os.makedirs(models_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hH6Tdz2XCkp"
      },
      "source": [
        "Check if the gpu is being used or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SP9mUYU4F0a",
        "outputId": "2ab0b483-4076-467f-c39a-42b7a4bd4b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvGAeC6A-d3N"
      },
      "source": [
        "## Load data and preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OInIJ5s2-d3N"
      },
      "source": [
        "Firstly, the data is loaded from the train, dev and test files into a list of sentences.\n",
        "\n",
        "Preprocessing:\n",
        "\n",
        "    * All the digits in the words are replaced by 0\n",
        "    \n",
        "Why this preprocessing step?\n",
        "    * For the Named Entity Recognition task, the information present in numerical digits doesnot help in predicting the entity. So, we replace all the digits by 0. So, now the model can concentrate on more important alphabets.\n",
        "\n",
        "Note: For the task of error extraction, we will skip the process of replacing all digits by 0 -> parameters['zeros'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79J0NvUO-d3O"
      },
      "outputs": [],
      "source": [
        "def zero_digits(string):\n",
        "    # This function will replace all the digits in a string to 0s\n",
        "    return re.sub('\\d', '0', string)\n",
        "\n",
        "def load_sentences(path, zeros):\n",
        "    # A function help loading sentences from the dataset\n",
        "    # A line in the dataset must contain at least 2 parts: word and its tag\n",
        "    # In this project's dataset, a line only contains 2 parts: word and its NER tag (in BIO2 format)\n",
        "    # A sentence is the combination of many lines (words) and each sentence gets separated by an empty line\n",
        "\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in codecs.open(path, 'r', 'utf8'):\n",
        "        # If we want to replace the digits with zeros then by the time we read a line from a file we also replace the number(s) in that line with zero(s).\n",
        "        # Otherwise we just read a line without replacing any numbers with zeros\n",
        "        line = zero_digits(line.rstrip()) if zeros else line.rstrip()\n",
        "\n",
        "        # Check for empty line = end of a sentence\n",
        "        if not line:\n",
        "            # We only add the sentence if it has word(s) inside\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "        # If not an empty line, keep adding words to form the full sentence\n",
        "        else:\n",
        "            word = line.split()\n",
        "            assert len(word) >= 2     # Check to make sure that each line only has two parts: word and its NER tag\n",
        "            sentence.append(word)\n",
        "\n",
        "    # If we reach the end of the file but we still have not added the final sentence\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9amSirx-d3O"
      },
      "outputs": [],
      "source": [
        "train_sentences = load_sentences(parameters['train'], parameters['zeros'])\n",
        "test_sentences = load_sentences(parameters['test'], parameters['zeros'])\n",
        "dev_sentences = load_sentences(parameters['dev'], parameters['zeros'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otmQ5xzECzVG",
        "outputId": "3659a511-ff2a-4b5a-fe89-b1147503ed4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of sentences in training set: 5027\n",
            "The number of sentences in testing set: 3000\n",
            "The number of sentences in development set: 2000\n"
          ]
        }
      ],
      "source": [
        "print('The number of sentences in training set:',len(train_sentences))\n",
        "print('The number of sentences in testing set:',len(test_sentences))\n",
        "print('The number of sentences in development set:',len(dev_sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNhrVJCB-d3P"
      },
      "source": [
        "## Update tagging scheme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fq07WSF-d3P"
      },
      "source": [
        "As mentioned before, we will only apply updating the tagging scheme from BIO2 to BIOES to match with the results in the reasearch paper. For the task of model evaluation, we will skip this update tagging scheme step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIQVfxaB-d3P"
      },
      "outputs": [],
      "source": [
        "def iob2(tags):\n",
        "    # This function serves 2 purposes:\n",
        "    # 1. To check if the NER tag is in the BIO format: VALID -> PASS, INVALID -> STOP\n",
        "    # 2. Update the tagging scheme from BIO1 to BIO2 format\n",
        "\n",
        "    for i, tag in enumerate(tags):\n",
        "        if tag == 'O':\n",
        "            continue\n",
        "        split = tag.split('-')\n",
        "        if len(split) != 2 or split[0] not in ['I', 'B']:\n",
        "            return False\n",
        "        if split[0] == 'B':\n",
        "            continue\n",
        "        elif i == 0 or tags[i - 1] == 'O':  # conversion IOB1 to IOB2\n",
        "            tags[i] = 'B' + tag[1:]\n",
        "        elif tags[i - 1][1:] == tag[1:]:\n",
        "            continue\n",
        "        else:  # conversion IOB1 to IOB2\n",
        "            tags[i] = 'B' + tag[1:]\n",
        "    return True\n",
        "\n",
        "def iob_iobes(tags):\n",
        "    # This functions also serves 2 purposes:\n",
        "    # 1. To check if the NER tag is in the BIO format: VALID -> PASS, INVALID -> STOP\n",
        "    # 2. Update the tagging scheme from BIO2 to IOBES format\n",
        "\n",
        "    new_tags = []\n",
        "    for i, tag in enumerate(tags):\n",
        "        if tag == 'O':\n",
        "            new_tags.append(tag)\n",
        "        elif tag.split('-')[0] == 'B':\n",
        "            if i + 1 != len(tags) and \\\n",
        "               tags[i + 1].split('-')[0] == 'I':\n",
        "                new_tags.append(tag)\n",
        "            else:\n",
        "                new_tags.append(tag.replace('B-', 'S-'))\n",
        "        elif tag.split('-')[0] == 'I':\n",
        "            if i + 1 < len(tags) and \\\n",
        "                    tags[i + 1].split('-')[0] == 'I':\n",
        "                new_tags.append(tag)\n",
        "            else:\n",
        "                new_tags.append(tag.replace('I-', 'E-'))\n",
        "        else:\n",
        "            raise Exception('Invalid IOB format!')\n",
        "    return new_tags\n",
        "\n",
        "def update_tag_scheme(sentences, tag_scheme):\n",
        "    # This function calls the 2 above functions:\n",
        "    # Check if the tagging scheme in IOB format and update BIO1 to BIO2 format\n",
        "    # Check if the tagging scheme in IOB format and update BIO2 to IOBES format\n",
        "\n",
        "    for i, s in enumerate(sentences):\n",
        "        tags = [w[-1] for w in s]\n",
        "        # Check that tags are given in the BIO format\n",
        "        if not iob2(tags):\n",
        "            s_str = '\\n'.join(' '.join(w) for w in s)\n",
        "            raise Exception('Sentences should be given in BIO format! ' +\n",
        "                            'Please check sentence %i:\\n%s' % (i, s_str))\n",
        "        if tag_scheme == 'BIOES':\n",
        "            new_tags = iob_iobes(tags)\n",
        "            for word, new_tag in zip(s, new_tags):\n",
        "                word[-1] = new_tag\n",
        "        else:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q72Xhka-d3Q"
      },
      "outputs": [],
      "source": [
        "update_tag_scheme(train_sentences, parameters['tag_scheme'])\n",
        "update_tag_scheme(dev_sentences, parameters['tag_scheme'])\n",
        "update_tag_scheme(test_sentences, parameters['tag_scheme'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD7JWwd5-d3Q"
      },
      "source": [
        "## Create Mappings for Words, Characters and Tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSkqR2hi-d3Q"
      },
      "source": [
        "In the step of applying mapping for words, characters in each words and tags, we want to map individual words, characters in each word and tags to unique numerical ID's."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69PduYwb-d3R"
      },
      "source": [
        "## Why mapping is important?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfJeCPzx-d3R"
      },
      "source": [
        "With the indices for words, characters and tags, we will be able to employ matrix (tensors) operations inside the neural network architecture, which are significantly faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h0jDKw1-d3R"
      },
      "outputs": [],
      "source": [
        "def create_item_dictionary(list_items):\n",
        "    # This function will create a dictionary with:\n",
        "    # + Key depends on the item in the list_items\n",
        "    # + Value is the total number of time the value of the corresponding key appears\n",
        "\n",
        "    assert type(list_items) is list\n",
        "    item_dict = {}\n",
        "    for items in list_items:\n",
        "        for item in items:\n",
        "            if item not in item_dict:\n",
        "                item_dict[item] = 1\n",
        "            else:\n",
        "                item_dict[item] += 1\n",
        "    return item_dict\n",
        "\n",
        "def create_mapping(item_dict):\n",
        "    # This function will help mapping based on the value of the item_dict:\n",
        "    # The higher the value the smaller the index the key will have\n",
        "\n",
        "    sorted_items = sorted(item_dict.items(), key=lambda x: (-x[1], x[0]))\n",
        "    id_to_item = {index: item[0] for index, item in enumerate(sorted_items)}\n",
        "    item_to_id = {item: index for index, item in id_to_item.items()}\n",
        "    return item_to_id, id_to_item\n",
        "\n",
        "def word_mapping(sentences, lower):\n",
        "    # In this function, we will:\n",
        "    # 1. Create a dictionary with key is each word and value is its total number of time appearing in the dataset\n",
        "    # 2. Create mapping based on each value of the dictionary, the more a word appears the smaller index it will have\n",
        "\n",
        "    words = [[word[0].lower() if lower else word[0] for word in sentence] for sentence in sentences]\n",
        "    word_dict = create_item_dictionary(words)\n",
        "    word_dict['<UNK>'] = 10000000 # <UNK> tag is for unknown words\n",
        "    word_to_id, id_to_word = create_mapping(word_dict)\n",
        "    print(\"Found %i unique words (%i in total)\" % (\n",
        "        len(word_dict), sum(len(word) for word in words)\n",
        "    ))\n",
        "    return word_dict, word_to_id, id_to_word\n",
        "\n",
        "def char_mapping(sentences):\n",
        "    # In this function, we will:\n",
        "    # 1. Create a dictionary with key is each character and value is its total number of time appearing in the dataset\n",
        "    # 2. Create mapping based on each value of the dictionary, the more a character appears the smaller index it will have\n",
        "\n",
        "    chars = [\"\".join([word[0] for word in sentence]) for sentence in sentences]\n",
        "    char_dict = create_item_dictionary(chars)\n",
        "    char_to_id, id_to_char = create_mapping(char_dict)\n",
        "    print(\"Found %i unique characters\" % len(char_dict))\n",
        "    return char_dict, char_to_id, id_to_char\n",
        "\n",
        "def tag_mapping(sentences):\n",
        "    # In this function, we will:\n",
        "    # 1. Create a dictionary with key is each tag and value is its total number of time appearing in the dataset\n",
        "    # 2. Create mapping based on each value of the dictionary, the more a tag appears the smaller index it will have\n",
        "\n",
        "    tags = [[word[-1] for word in sentence] for sentence in sentences]\n",
        "    tag_dict = create_item_dictionary(tags)\n",
        "    tag_dict[START_TAG] = -1       # The index of the <START> tag will be the index right just before the final index (<STOP> tag)\n",
        "    tag_dict[STOP_TAG] = -2        # The index of the <STOP> tag will be the final index\n",
        "    tag_to_id, id_to_tag = create_mapping(tag_dict)\n",
        "    print(\"Found %i unique named entity tags\" % len(tag_dict))\n",
        "    return tag_dict, tag_to_id, id_to_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd0oDmUu-d3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04c7f8f-a8ae-4540-9cf8-144f245afb71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4740 unique words (132511 in total)\n",
            "Found 176 unique characters\n",
            "Found 22 unique named entity tags\n"
          ]
        }
      ],
      "source": [
        "word_dict, word_to_id, id_to_word = word_mapping(train_sentences, parameters['lower'])\n",
        "char_dict, char_to_id, id_to_char = char_mapping(train_sentences)\n",
        "tag_dict, tag_to_id, id_to_tag = tag_mapping(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tag_to_id['I-NAME'] = 38\n",
        "# tag_to_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SOKGRcjOKxC",
        "outputId": "19567e5f-913d-4fbb-8c43-3499f2b8788c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'S-PATIENT_ID': 1,\n",
              " 'B-LOCATION': 2,\n",
              " 'E-LOCATION': 3,\n",
              " 'S-LOCATION': 4,\n",
              " 'I-LOCATION': 5,\n",
              " 'I-ORGANIZATION': 6,\n",
              " 'S-DATE': 7,\n",
              " 'B-DATE': 8,\n",
              " 'E-DATE': 9,\n",
              " 'I-DATE': 10,\n",
              " 'B-ORGANIZATION': 11,\n",
              " 'E-ORGANIZATION': 12,\n",
              " 'B-SYMPTOM_AND_DISEASE': 13,\n",
              " 'E-SYMPTOM_AND_DISEASE': 14,\n",
              " 'S-AGE': 15,\n",
              " 'I-SYMPTOM_AND_DISEASE': 16,\n",
              " 'S-GENDER': 17,\n",
              " 'S-SYMPTOM_AND_DISEASE': 18,\n",
              " 'S-NAME': 19,\n",
              " 'S-TRANSPORTATION': 20,\n",
              " 'S-JOB': 21,\n",
              " 'B-TRANSPORTATION': 22,\n",
              " 'E-TRANSPORTATION': 23,\n",
              " 'S-ORGANIZATION': 24,\n",
              " 'B-JOB': 25,\n",
              " 'E-JOB': 26,\n",
              " 'I-JOB': 27,\n",
              " 'B-NAME': 28,\n",
              " 'E-NAME': 29,\n",
              " 'I-TRANSPORTATION': 30,\n",
              " 'B-PATIENT_ID': 31,\n",
              " 'E-PATIENT_ID': 32,\n",
              " 'I-PATIENT_ID': 33,\n",
              " 'B-AGE': 34,\n",
              " 'E-AGE': 35,\n",
              " '<START>': 36,\n",
              " '<STOP>': 37,\n",
              " 'I-NAME': 38}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_E_rnhR-d3T"
      },
      "source": [
        "## Preparing final dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoSVFzNW-d3U"
      },
      "source": [
        "The function prepare dataset returns a list of dictionaries ( one dictionary per each sentence ) -> Train sentence: 1 dictionary, Validation sentence: 1 dictionary, Test sentence: 1 dictionary\n",
        "\n",
        "Each of the dictionary returned by the function contains:\n",
        "    \n",
        "    1. List of all words in the sentence (train, validation or test)\n",
        "    2. List of word index for all words in the sentence\n",
        "    3. List of lists, containing character id of each character for words in the sentence\n",
        "    4. List of tag for each word in the sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiTDurcF-d3U"
      },
      "outputs": [],
      "source": [
        "def lower_case(word, lower=False):\n",
        "    # Base on the \"lower\" parameter to lowercase a word or not\n",
        "    if lower:\n",
        "        return word.lower()\n",
        "    else:\n",
        "        return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN98wvdi-d3U",
        "outputId": "2d7cb681-5200-41b7-dda1-08cbeee60327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5027 / 2000 / 3000 sentences in train / dev / test.\n"
          ]
        }
      ],
      "source": [
        "def prepare_dataset(sentences, word_to_id, char_to_id, tag_to_id, lower=False):\n",
        "    # A function to help us prepare the dataset, this function will return:\n",
        "    # List of words in a sentence, words index, characters index, tags index -> For 1 sentence -> Store in a dictionary\n",
        "    # The data variable will be a list and it will store the total number of sentences that appear in the dataset = the total number of dictionaries\n",
        "\n",
        "    data = []\n",
        "    for sentence in sentences:\n",
        "        list_words = [item[0] for item in sentence]\n",
        "        words_index = [word_to_id[lower_case(word,lower) if lower_case(word,lower) in word_to_id else '<UNK>']\n",
        "                 for word in list_words]\n",
        "        # Skip characters that are not in the training set\n",
        "        chars_index = [[char_to_id[char] for char in word if char in char_to_id]\n",
        "                 for word in list_words]\n",
        "        tags_index = [tag_to_id[item[-1]] for item in sentence]\n",
        "        data.append({\n",
        "            'str_words': list_words,\n",
        "            'words': words_index,\n",
        "            'chars': chars_index,\n",
        "            'tags': tags_index,\n",
        "        })\n",
        "    return data\n",
        "\n",
        "train_data = prepare_dataset(\n",
        "    train_sentences, word_to_id, char_to_id, tag_to_id, parameters['lower']\n",
        ")\n",
        "dev_data = prepare_dataset(\n",
        "    dev_sentences, word_to_id, char_to_id, tag_to_id, parameters['lower']\n",
        ")\n",
        "test_data = prepare_dataset(\n",
        "    test_sentences, word_to_id, char_to_id, tag_to_id, parameters['lower']\n",
        ")\n",
        "print(\"{} / {} / {} sentences in train / dev / test.\".format(len(train_data), len(dev_data), len(test_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIwd4xMk-d3V"
      },
      "source": [
        "After the above step, the data is ready to be fitted to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTCRrXuL-d3V"
      },
      "source": [
        "## Load Word Embeddings\n",
        "\n",
        "Now, We move to the next step of loading the pre-trained word embeddings.\n",
        "\n",
        "We will use Word-2-vec vectors with 300 dimensions pre-trained on a 20GB corpus of Vietnamese texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzQXSHG4-d3V",
        "outputId": "f00f8504-55ba-4c59-c066-33149a25f567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 676322 pretrained embeddings.\n"
          ]
        }
      ],
      "source": [
        "all_word_embeds = {}\n",
        "for i, line in enumerate(codecs.open(parameters['embedding_path'], 'r', 'utf-8')):\n",
        "    s = line.strip().split()\n",
        "    if len(s) == parameters['word_dim'] + 1:\n",
        "        all_word_embeds[s[0]] = np.array([float(i) for i in s[1:]])\n",
        "\n",
        "#Intializing Word Embedding Matrix\n",
        "word_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (len(word_to_id), parameters['word_dim']))\n",
        "\n",
        "for w in word_to_id:\n",
        "    if w in all_word_embeds:\n",
        "        word_embeds[word_to_id[w]] = all_word_embeds[w]\n",
        "    elif w.lower() in all_word_embeds:\n",
        "        word_embeds[word_to_id[w]] = all_word_embeds[w.lower()]\n",
        "\n",
        "print('Loaded %i pretrained embeddings.' % len(all_word_embeds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQFPhdm4-d3V"
      },
      "source": [
        "## Storing Processed Data for Reuse\n",
        "\n",
        "We can store the preprocessed data and the embedding matrix for future reuse. This helps us avoid the time taken by the step of preprocessing, when we are trying to tune the hyper parameters for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzvH1PuA-d3V",
        "outputId": "58d53123-8b8d-430f-d175-afdb185e7b62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word_to_id:  4740\n"
          ]
        }
      ],
      "source": [
        "with open(mapping_file, 'wb') as f:\n",
        "    mappings = {\n",
        "        'word_to_id': word_to_id,\n",
        "        'tag_to_id': tag_to_id,\n",
        "        'char_to_id': char_to_id,\n",
        "        'parameters': parameters,\n",
        "        'word_embeds': word_embeds\n",
        "    }\n",
        "    cPickle.dump(mappings, f)\n",
        "\n",
        "print('word_to_id: ', len(word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT5li7VBsztF",
        "outputId": "cd5d5bd7-0b6b-429d-965b-f7649dd06e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_to_id:  4740\n",
            "tag_to_id: 22\n",
            "char_to_id: 176\n",
            "parameters: 21\n",
            "word_embeds: 4740\n"
          ]
        }
      ],
      "source": [
        "print('word_to_id: ', len(word_to_id))\n",
        "print('tag_to_id:', len(tag_to_id))\n",
        "print('char_to_id:', len(char_to_id))\n",
        "print('parameters:', len(parameters))\n",
        "print('word_embeds:', len(word_embeds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gbu0fdX-d3W"
      },
      "source": [
        "# Buidling the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHRRmwFj-d3W"
      },
      "source": [
        "The model that we are presenting is a complicated one, since its a hybridized network using LSTMs and CNNs. So in order to break down the complexity, we have attempted to simplify the process by splitting up operations into individual functions that we can go over part by part. This hopefully makes the whole thing more easily digestable and gives a more intuitive understanding of the whole process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ClFKfyF-d3W"
      },
      "source": [
        "## Initialization of weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDHcnar8-d3W"
      },
      "source": [
        "We start with the init_embedding function, which just initializes the embedding layer by pooling from a random sample.\n",
        "\n",
        "The distribution is pooled from $-\\sqrt{\\frac{3}{V}}$ to $+\\sqrt{\\frac{3}{V}}$ where $V$ is the embedding dimension size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWGe-DTU-d3X"
      },
      "outputs": [],
      "source": [
        "def init_embedding(input_embedding):\n",
        "    \"\"\"\n",
        "    Initialize embedding\n",
        "    \"\"\"\n",
        "    bias = np.sqrt(3.0 / input_embedding.size(1))\n",
        "    nn.init.uniform(input_embedding, -bias, bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEgi0BjP-d3X"
      },
      "source": [
        "Similar to the initialization above, except this is for the linear layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiDBDipI-d3X"
      },
      "outputs": [],
      "source": [
        "def init_linear(input_linear):\n",
        "    \"\"\"\n",
        "    Initialize linear transformation\n",
        "    \"\"\"\n",
        "    bias = np.sqrt(6.0 / (input_linear.weight.size(0) + input_linear.weight.size(1)))\n",
        "    nn.init.uniform(input_linear.weight, -bias, bias)\n",
        "    if input_linear.bias is not None:\n",
        "        input_linear.bias.data.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tpp6Ndf-d3X"
      },
      "source": [
        "This is the initialization scheme for the LSTM layers.\n",
        "\n",
        "The LSTM layers are initialized by uniform sampling from $-\\sqrt{\\frac{6}{r+c}}$ to $+\\sqrt{\\frac{6}{r+c}}$. Where $r$ is the number of rows, $c$ is the number of columns (based on the shape of the weight matrix)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZoB__aF-d3X"
      },
      "outputs": [],
      "source": [
        "def init_lstm(input_lstm):\n",
        "    \"\"\"\n",
        "    Initialize lstm\n",
        "\n",
        "    PyTorch weights parameters:\n",
        "\n",
        "        weight_ih_l[k]: the learnable input-hidden weights of the k-th layer,\n",
        "            of shape `(hidden_size * input_size)` for `k = 0`. Otherwise, the shape is\n",
        "            `(hidden_size * hidden_size)`\n",
        "\n",
        "        weight_hh_l[k]: the learnable hidden-hidden weights of the k-th layer,\n",
        "            of shape `(hidden_size * hidden_size)`\n",
        "    \"\"\"\n",
        "\n",
        "    # Weights init for forward layer\n",
        "    for ind in range(0, input_lstm.num_layers):\n",
        "\n",
        "        ## Gets the weights Tensor from our model, for the input-hidden weights in our current layer\n",
        "        weight = eval('input_lstm.weight_ih_l' + str(ind))\n",
        "\n",
        "        # Initialize the sampling range\n",
        "        sampling_range = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
        "\n",
        "        # Randomly sample from our samping range using uniform distribution and apply it to our current layer\n",
        "        nn.init.uniform(weight, -sampling_range, sampling_range)\n",
        "\n",
        "        # Similar to above but for the hidden-hidden weights of the current layer\n",
        "        weight = eval('input_lstm.weight_hh_l' + str(ind))\n",
        "        sampling_range = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
        "        nn.init.uniform(weight, -sampling_range, sampling_range)\n",
        "\n",
        "\n",
        "    # We do the above again, for the backward layer if we are using a bi-directional LSTM (our final model uses this)\n",
        "    if input_lstm.bidirectional:\n",
        "        for ind in range(0, input_lstm.num_layers):\n",
        "            weight = eval('input_lstm.weight_ih_l' + str(ind) + '_reverse')\n",
        "            sampling_range = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
        "            nn.init.uniform(weight, -sampling_range, sampling_range)\n",
        "            weight = eval('input_lstm.weight_hh_l' + str(ind) + '_reverse')\n",
        "            sampling_range = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
        "            nn.init.uniform(weight, -sampling_range, sampling_range)\n",
        "\n",
        "    # Bias initialization steps\n",
        "\n",
        "    # We initialize them to zero except for the forget gate bias, which is initialized to 1\n",
        "    if input_lstm.bias:\n",
        "        for ind in range(0, input_lstm.num_layers):\n",
        "            bias = eval('input_lstm.bias_ih_l' + str(ind))\n",
        "\n",
        "            # Initializing to zero\n",
        "            bias.data.zero_()\n",
        "\n",
        "            # This is the range of indices for our forget gates for each LSTM cell\n",
        "            bias.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
        "\n",
        "            #Similar for the hidden-hidden layer\n",
        "            bias = eval('input_lstm.bias_hh_l' + str(ind))\n",
        "            bias.data.zero_()\n",
        "            bias.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
        "\n",
        "        # Similar to above, we do for backward layer if we are using a bi-directional LSTM\n",
        "        if input_lstm.bidirectional:\n",
        "            for ind in range(0, input_lstm.num_layers):\n",
        "                bias = eval('input_lstm.bias_ih_l' + str(ind) + '_reverse')\n",
        "                bias.data.zero_()\n",
        "                bias.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
        "                bias = eval('input_lstm.bias_hh_l' + str(ind) + '_reverse')\n",
        "                bias.data.zero_()\n",
        "                bias.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip5h-s4B-d3Y"
      },
      "source": [
        "## CRF Layer\n",
        "\n",
        "- Without the CRF Layer the model can already predicted the labels but the accuracy score would be considerably low since there are no rules or constraint for the model to know which tags should not follow some tags.\n",
        "- With the help the CRF layer, it will apply some rules relate to the tags so that the model will predict the labels much more precisely.\n",
        "- For example: CRF layer will add a rule that B-PERSON cannot be followed by I-ORGANIZATION."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1d0hXNI-d3Z"
      },
      "source": [
        "## Evaluation schemes: Forward pass and Viterbi algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIMusU3i-d3Z"
      },
      "source": [
        "- The forward pass will help us calculate the score of all possible paths.\n",
        "- The viterbi algorithm will help us calculate not only the score of the best path but also the best path itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukxy-CS7-d3Z"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCFq_Buc-d3Z"
      },
      "source": [
        "Now, we define some helper functions for numerical operations and score calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlAYlpP6-d3a"
      },
      "outputs": [],
      "source": [
        "def log_sum_exp(vec):\n",
        "    # This function applies log, sum and exp to calculate the score of all possible paths\n",
        "    # Before applying the log, sum and exp, we need to turn the score to numerically stable version in order to avoid the overflow situation\n",
        "    # vec's size: (1, tagset_size)\n",
        "\n",
        "    # print(\"Arg max of vec: \", argmax(vec))\n",
        "\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "def argmax(vec):\n",
        "    # This function will return the index of the max value in a vector\n",
        "\n",
        "    _, index = torch.max(vec, 1) # idx is a tensor and inside of it only has 1 value\n",
        "    return to_scalar(index)\n",
        "\n",
        "def to_scalar(var):\n",
        "    '''\n",
        "    Function to convert pytorch tensor to a scalar\n",
        "    '''\n",
        "\n",
        "    # This function will turn a tensor to a scalar:\n",
        "    # Step 1: Flatten the tensor to a 1-D array\n",
        "    # Step 2: Pick the first element of the array\n",
        "\n",
        "    return var.view(-1).data.tolist()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trmqvhzO-d3a"
      },
      "source": [
        "## Helper function to calculate score\n",
        "\n",
        "This is a score function for our sentences.\n",
        "\n",
        "This function takes two things, a list of ground truths that tell us what the corresponding tags are, the other are the features which contains the supposed tagged parts of the function. Which is then used to compute the score.\n",
        "\n",
        "This function will calculate the score of the ground truth path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30rLkzTr-d3a"
      },
      "outputs": [],
      "source": [
        "def score_sentences(self, feats, tags):\n",
        "    # This function calculates the score of the correct sequence of tags\n",
        "    # tags is ground_truth, a list of ints, length is len(sentence)\n",
        "    # feats is a 2D tensor, with the size of: len(sentence) * tagset_size\n",
        "\n",
        "\n",
        "    r = torch.LongTensor(range(feats.size()[0]))    # range(number_of_words_in_1_sentence)\n",
        "    if self.use_gpu:\n",
        "        r = r.cuda()\n",
        "        pad_start_tags = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
        "        pad_stop_tags = torch.cat([tags, torch.cuda.LongTensor([self.tag_to_ix[STOP_TAG]])])\n",
        "    else:\n",
        "        pad_start_tags = torch.cat([torch.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
        "        pad_stop_tags = torch.cat([tags, torch.LongTensor([self.tag_to_ix[STOP_TAG]])])\n",
        "\n",
        "    # print(\"Transition scores: \", self.transitions[pad_stop_tags, pad_start_tags])\n",
        "\n",
        "    # score = trans_score + emit_score\n",
        "    score = torch.sum(self.transitions[pad_stop_tags, pad_start_tags]) + torch.sum(feats[r, tags])\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfQPqw6Q-d3a"
      },
      "source": [
        "## Implementation of Forward Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9c8O2kE-d3a"
      },
      "outputs": [],
      "source": [
        "def forward_alg(self, feats):\n",
        "    # This function calculates the score of all possible paths that a sentence can have or the partition function\n",
        "    # feats has the size of: len(sentence) * tagset_size\n",
        "\n",
        "    # Initialize alpha with a Tensor (with the size of (1, len(tagset_size))) with values all equal to -10000.\n",
        "    alpha = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
        "\n",
        "    # START_TAG = 0 means it will start with the <START> tag\n",
        "    alpha[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "    # Wrap in a variable so that we will get automatic backpropagation\n",
        "    forward_var = autograd.Variable(alpha)\n",
        "    if self.use_gpu:\n",
        "        forward_var = forward_var.cuda()\n",
        "\n",
        "    # Iterate through the sentence\n",
        "    for feat in feats:\n",
        "        # Broadcast the emission score to a tensor with the size of (len(tagset_size), 1)\n",
        "        emit_score = feat.view(-1, 1)\n",
        "\n",
        "        # Adding the transition score and emission score to the forward variable\n",
        "        tag_var = forward_var + self.transitions + emit_score\n",
        "\n",
        "        # Before applying the log, sum, exp function to the score above, we need to turn it numerically stable version\n",
        "        max_tag_var, _ = torch.max(tag_var, dim=1)\n",
        "        tag_var = tag_var - max_tag_var.view(-1, 1)\n",
        "\n",
        "        # After turning the score to a numerically stable version, we can apply log, sum, exp to the score\n",
        "        forward_var = max_tag_var + torch.log(torch.sum(torch.exp(tag_var), dim=1)).view(1, -1) # ).view(1, -1)\n",
        "\n",
        "\n",
        "    # Adding the transition score to the <STOP> tag before applying the log, sum, exp function the last time\n",
        "    terminal_var = (forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]).view(1, -1)\n",
        "    alpha = log_sum_exp(terminal_var)\n",
        "    # Z(x)\n",
        "    return alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMfsJt0e-d3b"
      },
      "source": [
        "## Viterbi decode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDcWDUvI-d3b"
      },
      "source": [
        "- Viterbi will calculate the scores of all possible paths and in the mean time it also stores the index of the tags that have the highes score to a back pointer.\n",
        "- The best score will be the final maximum score.\n",
        "- We will locate the index of the tag that has the maximum score and with the help of the back pointer we will be able to find the best path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl5tvIUN-d3b"
      },
      "outputs": [],
      "source": [
        "def viterbi_algo(self, feats):\n",
        "    # In this function we will implement the viterbi algorithm to find the best sequence of tags of a sentence\n",
        "\n",
        "    # A list to store the index of the best previous tag for the current tag\n",
        "    backpointers = []\n",
        "\n",
        "    # Initialize the viterbi variables in log space\n",
        "    init_variable = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
        "\n",
        "    # START_TAG = 0 means it will start with the <START> tag\n",
        "    init_variable[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "    # forward_var at step i holds the viterbi variables for step i-1\n",
        "    forward_var = Variable(init_variable)\n",
        "    if self.use_gpu:\n",
        "        forward_var = forward_var.cuda()\n",
        "    for feat in feats:\n",
        "        next_tag_var = forward_var.view(1, -1).expand(self.tagset_size, self.tagset_size) + self.transitions\n",
        "        _, back_pointer = torch.max(next_tag_var, dim=1)\n",
        "        back_pointer = back_pointer.squeeze().data.cpu().numpy() # holds the backpointers for this step\n",
        "        next_tag_var = next_tag_var.data.cpu().numpy()\n",
        "        viterbivars_t = next_tag_var[range(len(back_pointer)), back_pointer] # holds the viterbi variables for this step\n",
        "        viterbivars_t = Variable(torch.FloatTensor(viterbivars_t))\n",
        "        if self.use_gpu:\n",
        "            viterbivars_t = viterbivars_t.cuda()\n",
        "\n",
        "        # Update the Viterbi score by adding the emission score here\n",
        "        forward_var = viterbivars_t + feat\n",
        "        backpointers.append(back_pointer)\n",
        "\n",
        "    # Add the forward variable with the transition score to STOP_TAG\n",
        "    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "    terminal_var.data[self.tag_to_ix[STOP_TAG]] = -10000.\n",
        "    terminal_var.data[self.tag_to_ix[START_TAG]] = -10000.\n",
        "    best_tag_id = argmax(terminal_var.unsqueeze(0))\n",
        "    path_score = terminal_var[best_tag_id]\n",
        "\n",
        "    # Follow the back pointers to decode the best path.\n",
        "    best_path = [best_tag_id]\n",
        "    for bptrs_t in reversed(backpointers):\n",
        "        best_tag_id = bptrs_t[best_tag_id]\n",
        "        best_path.append(best_tag_id)\n",
        "\n",
        "    # Pop off the start tag\n",
        "    start = best_path.pop()\n",
        "    assert start == self.tag_to_ix[START_TAG] # Make sure that we remove the start tag\n",
        "    best_path.reverse()\n",
        "    return path_score, best_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below function will be used to call the viterbi algorithm"
      ],
      "metadata": {
        "id": "zKxPHIGpU-Qe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY1O2fBE-d3c"
      },
      "outputs": [],
      "source": [
        "def forward_calc(self, sentence, chars, chars2_length):\n",
        "    # This function calls the above viterbi algorithm to return the best sequence of tags\n",
        "\n",
        "    # Get the emission scores from the BiLSTM model\n",
        "    # feats = self._get_lstm_features(sentence, chars, chars2_length, d)\n",
        "    feats = self._get_lstm_features(sentence, chars, chars2_length)\n",
        "\n",
        "\n",
        "    # With the given features, apply the viterbi algorithm to find the best path\n",
        "    if self.use_crf:\n",
        "        score, tag_seq = self.viterbi_decode(feats)\n",
        "    else:\n",
        "        score, tag_seq = torch.max(feats, 1)\n",
        "        tag_seq = list(tag_seq.cpu().data)\n",
        "\n",
        "    return score, tag_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIZzd6aN-d3c"
      },
      "source": [
        "## Details fo the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzecx2tT-d3c"
      },
      "source": [
        "##### 1. CNN model for generating character embeddings\n",
        "\n",
        "\n",
        "Consider the word 'cat', we pad it on both ends to get our maximum word length ( this is mainly an implementation quirk since we can't have variable length layers at run time, our algorithm will ignore the pads).\n",
        "\n",
        "We then apply a convolution layer on top that generates spatial coherence across characters, we use a maxpool to extract meaningful features out of our convolution layer. This now gives us a dense vector representation of each word. This representation will be concatenated with the pre-trained GloVe embeddings using a simple lookup.\n",
        "\n",
        "\n",
        "<img src = \"https://github.com/TheAnig/NER-LSTM-CNN-Pytorch/raw/master/images/cnn_model.png\"></img>\n",
        "<a href=\"http://www.aclweb.org/anthology/P16-1101\">Image Source</a>\n",
        "\n",
        "\n",
        "This snippet shows us how the CNN is implemented in pytorch\n",
        "\n",
        "`self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2,0))`\n",
        "\n",
        "##### 2. Rest of the model (LSTM based) that generates tags for the given sequence\n",
        "\n",
        "The word-embeddings( glove+char embedding ) that we generated above, we feed to a bi-directional LSTM model. The LSTM model has 2 layers,\n",
        "* The forward layer takes in a sequence of word vectors and generates a new vector based on what it has seen so far in the forward direction (starting from the start word up until current word) this vector can be thought of as a summary of all the words it has seen.\n",
        "\n",
        "* The backwards layer does the same but in opposite direction, i.e., from the end of the sentence to the current word.\n",
        "\n",
        "The forward vector and the backwards vector at current word concatanate to generate a unified representation.\n",
        "\n",
        "<img src = \"https://github.com/TheAnig/NER-LSTM-CNN-Pytorch/raw/master/images/lstm_model.png\"></img>\n",
        "<a href=\"http://www.aclweb.org/anthology/P16-1101\">Image Source</a>\n",
        "\n",
        "This snippet shows us how the BiLSTM is implemented in pytorch\n",
        "\n",
        "`self.lstm = nn.LSTM(embedding_dim+self.out_channels, hidden_dim, bidirectional=True)`\n",
        "\n",
        "Finally, we have a linear layer to map hidden vectors to tag space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P_P8hSu-d3c"
      },
      "source": [
        "##### Main Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT2kQtn8-d3c"
      },
      "source": [
        "The get_lstm_features function returns the LSTM's tag vectors. The function performs all the steps mentioned above for the model.\n",
        "\n",
        "Steps:\n",
        "1. It takes in Characters Embedding, reshapes its size to prepare for 2D convolution. The CNN extracts local features (trigrams here) from the sequence of character embeddings, capturing patterns like prefixes, suffixes, or syllable structures that are relevant for NER. Max pooling will then be applied to select the most salient features from the CNN output. This will produce the Character-level representation.\n",
        "2. We concat Character-level representation with Word Embedding, use this as features that we feed to Bidirectional-LSTM.\n",
        "3. The Bidirectional-LSTM generates outputs based on these set of features.\n",
        "4. The outputs are passed through a linear layer to convert to tag space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC60wLTL-d3d"
      },
      "outputs": [],
      "source": [
        "def get_lstm_features(self, sentence, chars2, chars2_length):\n",
        "\n",
        "    # if self.char_mode == 'LSTM':\n",
        "\n",
        "    #         chars_embeds = self.char_embeds(chars2).transpose(0, 1)\n",
        "\n",
        "    #         packed = torch.nn.utils.rnn.pack_padded_sequence(chars_embeds, chars2_length)\n",
        "\n",
        "    #         lstm_out, _ = self.char_lstm(packed)\n",
        "\n",
        "    #         outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out)\n",
        "\n",
        "    #         outputs = outputs.transpose(0, 1)\n",
        "\n",
        "    #         chars_embeds_temp = Variable(torch.FloatTensor(torch.zeros((outputs.size(0), outputs.size(2)))))\n",
        "\n",
        "    #         if self.use_gpu:\n",
        "    #             chars_embeds_temp = chars_embeds_temp.cuda()\n",
        "\n",
        "    #         for i, index in enumerate(output_lengths):\n",
        "    #             chars_embeds_temp[i] = torch.cat((outputs[i, index-1, :self.char_lstm_dim], outputs[i, 0, self.char_lstm_dim:]))\n",
        "\n",
        "    #         chars_embeds = chars_embeds_temp.clone()\n",
        "\n",
        "    #         for i in range(chars_embeds.size(0)):\n",
        "    #             chars_embeds[d[i]] = chars_embeds_temp[i]\n",
        "\n",
        "\n",
        "    if self.char_mode == 'CNN':\n",
        "        chars_embeds = self.char_embeds(chars2).unsqueeze(1)\n",
        "\n",
        "        ## Creating Character level representation using Convolutional Neural Netowrk\n",
        "        ## followed by a Maxpooling Layer\n",
        "        chars_cnn_out3 = self.char_cnn3(chars_embeds)\n",
        "        chars_embeds = nn.functional.max_pool2d(chars_cnn_out3,\n",
        "                                             kernel_size=(chars_cnn_out3.size(2), 1)).view(chars_cnn_out3.size(0), self.out_channels)\n",
        "\n",
        "        ## Loading word embeddings\n",
        "    embeds = self.word_embeds(sentence)\n",
        "\n",
        "    ## We concatenate the word embeddings and the character level representation\n",
        "    ## to create unified representation for each word\n",
        "    embeds = torch.cat((embeds, chars_embeds), 1)\n",
        "\n",
        "    embeds = embeds.unsqueeze(1)\n",
        "\n",
        "    ## Dropout on the unified embeddings\n",
        "    embeds = self.dropout(embeds)\n",
        "\n",
        "    ## Word lstm\n",
        "    ## Takes words as input and generates a output at each step\n",
        "    lstm_out, _ = self.lstm(embeds)\n",
        "\n",
        "    ## Reshaping the outputs from the lstm layer\n",
        "    lstm_out = lstm_out.view(len(sentence), self.hidden_dim*2)\n",
        "\n",
        "    ## Dropout on the lstm output\n",
        "    lstm_out = self.dropout(lstm_out)\n",
        "\n",
        "    ## Linear layer converts the ouput vectors to tag space\n",
        "    lstm_feats = self.hidden2tag(lstm_out)\n",
        "\n",
        "    return lstm_feats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TKWMAPc-d3d"
      },
      "source": [
        "##### Funtion for Negative log likelihood calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrcMgNqh-d3d"
      },
      "source": [
        "This is a helper function that calculates the negative log likelihood.\n",
        "\n",
        "- This function will first calculate the emission matrix score which is the output of the Bi-LSTM.\n",
        "- Next, it will calculate the score of all posible paths by using the above forward algorithm\n",
        "- Next, it will calculate the score of the ground truth path by using the above score sentence\n",
        "- Finally, it will calculate the negative log likelihood value (loss value) by subtracting the score of all possible paths by the score of ground truth path.\n",
        "- We will then base on this loss value or negative log likelihood value to optimize the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8OHBK4E-d3d"
      },
      "outputs": [],
      "source": [
        "def get_neg_log_likelihood(self, sentence, tags, chars2, chars2_length):\n",
        "    # sentence, tags is a list of ints\n",
        "    # features is a 2D tensor, len(sentence) * self.tagset_size\n",
        "\n",
        "    # feats = self._get_lstm_features(sentence, chars2, chars2_length, d)\n",
        "\n",
        "    feats = self._get_lstm_features(sentence, chars2, chars2_length)\n",
        "\n",
        "    if self.use_crf:\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "    else:\n",
        "        tags = Variable(tags)\n",
        "        scores = nn.functional.cross_entropy(feats, tags)\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVEFWcsh-d3e"
      },
      "source": [
        "##### Main Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ1zerkw-d3e"
      },
      "outputs": [],
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim,\n",
        "                 char_to_ix=None, pre_word_embeds=None, char_out_dimension=25,char_embedding_dim=25, use_gpu=False\n",
        "                 , use_crf=True, char_mode='CNN'):\n",
        "        '''\n",
        "        Input parameters:\n",
        "\n",
        "                vocab_size= Size of vocabulary (int)\n",
        "                tag_to_ix = Dictionary that maps NER tags to indices\n",
        "                embedding_dim = Dimension of word embeddings (int)\n",
        "                hidden_dim = The hidden dimension of the LSTM layer (int)\n",
        "                char_to_ix = Dictionary that maps characters to indices\n",
        "                pre_word_embeds = Numpy array which provides mapping from word embeddings to word indices\n",
        "                char_out_dimension = Output dimension from the CNN encoder for character\n",
        "                char_embedding_dim = Dimension of the character embeddings\n",
        "                use_gpu = defines availability of GPU,\n",
        "                    when True: CUDA function calls are made\n",
        "                    else: Normal CPU function calls are made\n",
        "                use_crf = parameter which decides if you want to use the CRF layer for output decoding\n",
        "        '''\n",
        "\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "\n",
        "        #parameter initialization for the model\n",
        "        self.use_gpu = use_gpu\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.use_crf = use_crf\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.out_channels = char_out_dimension\n",
        "        self.char_mode = char_mode\n",
        "\n",
        "        if char_embedding_dim is not None:\n",
        "            self.char_embedding_dim = char_embedding_dim\n",
        "\n",
        "            #Initializing the character embedding layer\n",
        "            self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)\n",
        "            init_embedding(self.char_embeds.weight)\n",
        "\n",
        "            #Performing LSTM encoding on the character embeddings\n",
        "            # if self.char_mode == 'LSTM':\n",
        "            #     self.char_lstm = nn.LSTM(char_embedding_dim, char_lstm_dim, num_layers=1, bidirectional=True)\n",
        "            #     init_lstm(self.char_lstm)\n",
        "\n",
        "            #Performing CNN encoding on the character embeddings\n",
        "            if self.char_mode == 'CNN':\n",
        "                self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2,0))\n",
        "\n",
        "        #Creating Embedding layer with dimension of ( number of words * dimension of each word)\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if pre_word_embeds is not None:\n",
        "            #Initializes the word embeddings with pretrained word embeddings\n",
        "            self.pre_word_embeds = True\n",
        "            self.word_embeds.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))\n",
        "        else:\n",
        "            self.pre_word_embeds = False\n",
        "\n",
        "        #Initializing the dropout layer, with dropout specificed in parameters\n",
        "        self.dropout = nn.Dropout(parameters['dropout'])\n",
        "\n",
        "        #Lstm Layer:\n",
        "        #input dimension: word embedding dimension + character level representation\n",
        "        #bidirectional=True, specifies that we are using the bidirectional LSTM\n",
        "        # if self.char_mode == 'LSTM':\n",
        "        #     self.lstm = nn.LSTM(embedding_dim+char_lstm_dim*2, hidden_dim, bidirectional=True)\n",
        "\n",
        "        if self.char_mode == 'CNN':\n",
        "            self.lstm = nn.LSTM(embedding_dim+self.out_channels, hidden_dim, bidirectional=True)\n",
        "\n",
        "        #Initializing the lstm layer using predefined function for initialization\n",
        "        init_lstm(self.lstm)\n",
        "\n",
        "        # Linear layer which maps the output of the bidirectional LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim*2, self.tagset_size)\n",
        "\n",
        "        #Initializing the linear layer using predefined function for initialization\n",
        "        init_linear(self.hidden2tag)\n",
        "\n",
        "        if self.use_crf:\n",
        "            # Matrix of transition parameters.  Entry i,j is the score of transitioning *to* i *from* j.\n",
        "            # Matrix has a dimension of (total number of tags * total number of tags)\n",
        "            self.transitions = nn.Parameter(\n",
        "                torch.zeros(self.tagset_size, self.tagset_size))\n",
        "\n",
        "            # These two statements enforce the constraint that we never transfer\n",
        "            # to the start tag and we never transfer from the stop tag\n",
        "            self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "            self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "    #assigning the functions, which we have defined earlier\n",
        "    _score_sentence = score_sentences\n",
        "    _get_lstm_features = get_lstm_features\n",
        "    _forward_alg = forward_alg\n",
        "    viterbi_decode = viterbi_algo\n",
        "    neg_log_likelihood = get_neg_log_likelihood\n",
        "    forward = forward_calc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model initialiaztion"
      ],
      "metadata": {
        "id": "4uSmPzScOuZc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8LYAfJg-d3e",
        "outputId": "4ceeabab-36f3-4c84-def8-8547365f3b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Initialized!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-db3aa24d91b1>:6: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
            "  nn.init.uniform(input_embedding, -bias, bias)\n",
            "<ipython-input-22-c489f95df697>:25: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
            "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
            "<ipython-input-22-c489f95df697>:30: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
            "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
            "<ipython-input-22-c489f95df697>:38: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
            "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
            "<ipython-input-22-c489f95df697>:41: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
            "  nn.init.uniform(weight, -sampling_range, sampling_range)\n"
          ]
        }
      ],
      "source": [
        "#creating the model using the Class defined above\n",
        "model = BiLSTM_CRF(vocab_size=len(word_to_id),\n",
        "                   tag_to_ix=tag_to_id,\n",
        "                   embedding_dim=parameters['word_dim'],\n",
        "                   hidden_dim=parameters['word_lstm_dim'],\n",
        "                   use_gpu=use_gpu,\n",
        "                   char_to_ix=char_to_id,\n",
        "                   pre_word_embeds=word_embeds,\n",
        "                   use_crf=parameters['crf'],\n",
        "                   char_mode=parameters['char_mode'],\n",
        "                   char_out_dimension = 50)\n",
        "print(\"Model Initialized!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check model's paramters and switch the model to run on GPU"
      ],
      "metadata": {
        "id": "qDYr2HiaSFlm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dhP8b-4-d3e",
        "outputId": "d628d43d-ee1a-4a98-9d49-e3973e092398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transitions\n",
            "char_embeds.weight\n",
            "char_cnn3.weight\n",
            "char_cnn3.bias\n",
            "word_embeds.weight\n",
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l0_reverse\n",
            "lstm.weight_hh_l0_reverse\n",
            "lstm.bias_ih_l0_reverse\n",
            "lstm.bias_hh_l0_reverse\n",
            "hidden2tag.weight\n",
            "hidden2tag.bias\n",
            "BiLSTM_CRF(\n",
            "  (char_embeds): Embedding(176, 25)\n",
            "  (char_cnn3): Conv2d(1, 50, kernel_size=(3, 25), stride=(1, 1), padding=(2, 0))\n",
            "  (word_embeds): Embedding(4740, 300)\n",
            "  (dropout): Dropout(p=0.75, inplace=False)\n",
            "  (lstm): LSTM(350, 200, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=400, out_features=22, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Print the model's parameters\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  print(name)\n",
        "\n",
        "if use_gpu:\n",
        "    # model.cuda()\n",
        "    print(model.cuda())\n",
        "\n",
        "# print(f\"Model's parameters after: {model.parameters}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEUgWwyZ-d3f"
      },
      "source": [
        "# Evaluation\n",
        "- This evaluating step will also be used during the training process to:\n",
        "  - Evaluate the model\n",
        "  - Calculate the F1 score on the validation set to find the best F1 score in order to save to the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOXAu0Le-d3f"
      },
      "source": [
        "## We will define 2 helper functions for the evaluation function\n",
        "Those 2 functions are:\n",
        "- get_chunk_type: This function will help us split the entity tag into 2 parts: entity class (B, I, O, E or S) and entity type (PATIENT_ID, PERSON_NAME, AGE, ...)\n",
        "- get_chunks: This function will help us change the format of the output of the entire model, which is a sequence of tag's ids in a sentence, to a more convient one to evaluate the model. Specifically, this function will turn the sequence of tag's ids to a list of tuples and in each of those tuples will have three item:\n",
        "  - chunk_type: Which is the type of the entity\n",
        "  - chunk_start: Which is the start index of the entity type in the sentence\n",
        "  - chunk_end: Which is the end index of the entity type in the sentence. Please note that the chunk_index is excluded which means that the entity type will start at the index of chunk_start and end at the index of chunk_end - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_oGhjmg-d3f"
      },
      "outputs": [],
      "source": [
        "def get_chunk_type(tok, idx_to_tag):\n",
        "    # This function takes in 2 arguments:\n",
        "    # tok: id of the entity tag, for example: 2\n",
        "    # idx_to_tag: a dictionary with key is the id and the value is the corresponding entity tag (For example: key: 1, value: \"B-PERSON_NAME\")\n",
        "\n",
        "    # This function helps us splitting the entity tag (chunk) into 2 parts, after achieving the entity tag by passing the tok to idx_to_tag\n",
        "    # The 2 parts:\n",
        "    # + The type part: B, I, O, E or S\n",
        "    # + The class part: PATIENT_ID, PERSON_NAME, AGE, LOCATION,...\n",
        "\n",
        "    # We pass in the id of the tag to get the tag name\n",
        "    tag_name = idx_to_tag[tok]\n",
        "\n",
        "    # We split the tag name into 2 parts:\n",
        "    # The class: B, I, O, E, S\n",
        "    tag_class = tag_name.split('-')[0]\n",
        "\n",
        "    # The type: PATIENT_ID, PERSON_NAME, AGE, GENDER, LOCATION,...\n",
        "    tag_type = tag_name.split('-')[-1]\n",
        "\n",
        "    return tag_class, tag_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1tgP1ba-d3g"
      },
      "outputs": [],
      "source": [
        "def get_chunks(seq, tags):\n",
        "    # This function takes in 2 arguments:\n",
        "    # seq: Sequence of ids of the tags with the length = len(sentence)\n",
        "    # tags: a dictionary with key is the tag name and the value is its corresponding id\n",
        "\n",
        "    # This function will return:\n",
        "    # A list of tuple (chunks) and in each tuple (chunk) there are three items: chunk_type, chunk_start, chunk_end + 1\n",
        "    # For example: chunk = (PERSON, 0, 3) -> The \"PERSON\" type will start at the index 0 and end at the index of 2 in the sentence\n",
        "    # Please note that this function only consider entity as a chunk, those with O chunk_type are not considered chunks.\n",
        "\n",
        "    # We assume by default the tags lie outside a named entity\n",
        "    default = tags[\"O\"]\n",
        "\n",
        "    # Store the tag_to_id dictionary's key (tag) and value (id)\n",
        "    # as a dictionary with key is the id and the value is the tag\n",
        "    idx_to_tag = {idx: tag for tag, idx in tags.items()}\n",
        "\n",
        "    chunks = []\n",
        "\n",
        "    # This variable will store the type of chunk\n",
        "    chunk_type = None\n",
        "\n",
        "    # This variable will store the start index of the type chunk\n",
        "    chunk_start = None\n",
        "\n",
        "    for i, tok in enumerate(seq):\n",
        "        # End of a chunk 1\n",
        "        if tok == default and chunk_type is not None:\n",
        "            # Add a chunk.\n",
        "            chunk = (chunk_type, chunk_start, i)\n",
        "            chunks.append(chunk)\n",
        "            chunk_type, chunk_start = None, None\n",
        "\n",
        "        # End of a chunk + start of a chunk!\n",
        "        elif tok != default:\n",
        "            tok_chunk_class, tok_chunk_type = get_chunk_type(tok, idx_to_tag)\n",
        "            if chunk_type is None:\n",
        "                # Initialize chunk for each entity\n",
        "                chunk_type, chunk_start = tok_chunk_type, i\n",
        "            elif tok_chunk_type != chunk_type or tok_chunk_class == \"B\":\n",
        "                # If chunk class is B, i.e., its a beginning of a new named entity\n",
        "                # or, if the chunk type is different from the previous one, then we\n",
        "                # start labelling it as a new entity\n",
        "                chunk = (chunk_type, chunk_start, i)\n",
        "                chunks.append(chunk)\n",
        "                chunk_type, chunk_start = tok_chunk_type, i\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    # A condition to check if the entity (chunk) lies at the end of a sentence\n",
        "    if chunk_type is not None:\n",
        "        chunk = (chunk_type, chunk_start, len(seq))\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the help of the 2 above functions, we can now implement the evaluating function"
      ],
      "metadata": {
        "id": "aAwQAqIjRhmQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU2W7i8g-d3g"
      },
      "outputs": [],
      "source": [
        "def evaluating(model, datas, best_F,dataset=\"Train\"):\n",
        "    '''\n",
        "    The function takes as input the model, data and calcuates F-1 Score\n",
        "    It performs conditional updates\n",
        "     1) Flag to save the model\n",
        "     2) Best F-1 score\n",
        "    ,if the F-1 score calculated improves on the previous F-1 score\n",
        "    '''\n",
        "    # Initializations\n",
        "    prediction = [] # A list that stores predicted tags\n",
        "    save = False # Flag that tells us if the model needs to be saved\n",
        "    new_F = 0.0 # Variable to store the current F1-Score (may not be the best)\n",
        "    correct_preds, total_correct, total_preds = 0., 0., 0. # Count variables\n",
        "\n",
        "    for data in datas:\n",
        "        ground_truth_id = data['tags']\n",
        "        words = data['str_words']\n",
        "        chars2 = data['chars']\n",
        "\n",
        "        # if parameters['char_mode'] == 'LSTM':\n",
        "        #     chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n",
        "        #     d = {}\n",
        "        #     for i, ci in enumerate(chars2):\n",
        "        #         for j, cj in enumerate(chars2_sorted):\n",
        "        #             if ci == cj and not j in d and not i in d.values():\n",
        "        #                 d[j] = i\n",
        "        #                 continue\n",
        "        #     chars2_length = [len(c) for c in chars2_sorted]\n",
        "        #     char_maxl = max(chars2_length)\n",
        "        #     chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n",
        "        #     for i, c in enumerate(chars2_sorted):\n",
        "        #         chars2_mask[i, :chars2_length[i]] = c\n",
        "        #     chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
        "\n",
        "        if parameters['char_mode'] == 'CNN':\n",
        "            # Padding the each word to max word size of that sentence\n",
        "            chars2_length = [len(c) for c in chars2]\n",
        "            char_maxl = max(chars2_length)\n",
        "            chars2_mask = np.zeros((len(chars2_length), char_maxl), dtype='int')\n",
        "            for i, c in enumerate(chars2):\n",
        "                chars2_mask[i, :chars2_length[i]] = c\n",
        "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
        "\n",
        "        dwords = Variable(torch.LongTensor(data['words']))\n",
        "\n",
        "        # We are getting the predicted output from our model\n",
        "        if use_gpu:\n",
        "            val,predict_tag_id = model(dwords.cuda(), chars2_mask.cuda(), chars2_length)\n",
        "        else:\n",
        "            val,predict_tag_id = model(dwords, chars2_mask, chars2_length)\n",
        "\n",
        "        # We use the get chunks function defined above to get the true chunks\n",
        "        # and the predicted chunks from true labels and predicted labels respectively\n",
        "        lab_chunks      = set(get_chunks(ground_truth_id,tag_to_id))\n",
        "        lab_pred_chunks = set(get_chunks(predict_tag_id,\n",
        "                                         tag_to_id))\n",
        "\n",
        "        # Updating the count variables\n",
        "        # By implementing intersection between the 2 sets (ground-truth and prediction), we will get the total number of correct predictions\n",
        "        correct_preds += len(lab_chunks & lab_pred_chunks)\n",
        "\n",
        "        # Update the number of predictions\n",
        "        total_preds   += len(lab_pred_chunks)\n",
        "\n",
        "        # Update the number of labels\n",
        "        total_correct += len(lab_chunks)\n",
        "\n",
        "    # Calculating the F1-Score\n",
        "    # F1 tính kiểu này là tính theo micro\n",
        "    # micro là tính toàn bộ không phân biệt class\n",
        "    # macro là lấy trung bình f1 của các class\n",
        "    p   = correct_preds / total_preds if correct_preds > 0 else 0\n",
        "    r   = correct_preds / total_correct if correct_preds > 0 else 0\n",
        "    new_F  = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
        "\n",
        "    print(\"{}: new_F: {} best_F: {} \".format(dataset,new_F,best_F))\n",
        "\n",
        "    # If our current F1-Score is better than the previous best, we update the best\n",
        "    # to current F1 and we set the flag to indicate that we need to checkpoint this model\n",
        "\n",
        "    if new_F>best_F:\n",
        "        best_F=new_F\n",
        "        save=True\n",
        "\n",
        "    return best_F, new_F, save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4P_vEvF-d3k"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training paramters which will be used during the training process"
      ],
      "metadata": {
        "id": "1NwuBTvNPW4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPNZe836PVJb"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001 # the same as VinAI paper\n",
        "number_of_epochs = parameters['epoch']\n",
        "decay_rate = 0.05\n",
        "gradient_clip = parameters['gradient_clip']\n",
        "# VinAI dùng Adam\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=learning_rate, betas=(0.9, 0.999))\n",
        "\n",
        "#variables which will used in training process\n",
        "losses = [] #list to store all losses\n",
        "loss = 0.0 #Loss Initializatoin\n",
        "best_dev_F = -1.0 # Current best F-1 Score on Dev Set\n",
        "best_train_F = -1.0 # Current best F-1 Score on Train Set\n",
        "eval_every = len(train_data) # Calculate F-1 Score after this many iterations\n",
        "plot_every = 2000 # Store loss after this many iterations\n",
        "count = 0 #Counts the number of iterations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A helper function to adjust the learning rate during the training process"
      ],
      "metadata": {
        "id": "Q1fsXaQgPhtr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NX6Drm0Pg7U"
      },
      "outputs": [],
      "source": [
        "def adjust_learning_rate(optimizer, lr):\n",
        "    \"\"\"\n",
        "    shrink learning rate\n",
        "    \"\"\"\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztk1z6rg-d3l"
      },
      "source": [
        "## Training time\n",
        "\n",
        "If `parameters['reload']` is set, we already have a model to load of off, so we can skip the training. We have originally specified a pre-trained model since training is an expensive process, but we encourage readers to try this out once they're done with the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1q3NFvGh-d3l",
        "outputId": "566a1ad8-7805-4cea-a0b2-8de73b575aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-ce1760f04c8d>:10: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  pad_start_tags = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
            "<ipython-input-38-0a1329fe7eb9>:56: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
            "  torch.nn.utils.clip_grad_norm(model.parameters(), gradient_clip)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000 :  tensor(0.4106, device='cuda:0')\n",
            "4000 :  tensor(0.1354, device='cuda:0')\n",
            "6000 :  tensor(0.1016, device='cuda:0')\n",
            "8000 :  tensor(0.0782, device='cuda:0')\n",
            "10000 :  tensor(0.0733, device='cuda:0')\n",
            "12000 :  tensor(0.0575, device='cuda:0')\n",
            "14000 :  tensor(0.0627, device='cuda:0')\n",
            "16000 :  tensor(0.0519, device='cuda:0')\n",
            "18000 :  tensor(0.0466, device='cuda:0')\n",
            "20000 :  tensor(0.0519, device='cuda:0')\n",
            "Train: new_F: 0.9703476805507311 best_F: -1.0 \n",
            "Dev: new_F: 0.9310298826040555 best_F: -1.0 \n",
            "New best F1 score on validation set: 0.9310298826040555\n",
            "Saving Model to  ./End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/models/model_word_version\n",
            "New F1 on Train: 0.9703476805507311 - New F1 on Validation: 0.9310298826040555\n",
            "22000 :  tensor(0.0385, device='cuda:0')\n",
            "24000 :  tensor(0.0501, device='cuda:0')\n",
            "26000 :  tensor(0.0364, device='cuda:0')\n",
            "28000 :  tensor(0.0415, device='cuda:0')\n",
            "30000 :  tensor(0.0361, device='cuda:0')\n",
            "32000 :  tensor(0.0358, device='cuda:0')\n",
            "34000 :  tensor(0.0326, device='cuda:0')\n",
            "36000 :  tensor(0.0399, device='cuda:0')\n",
            "38000 :  tensor(0.0330, device='cuda:0')\n",
            "40000 :  tensor(0.0360, device='cuda:0')\n",
            "Train: new_F: 0.9832182888987399 best_F: 0.9703476805507311 \n",
            "Dev: new_F: 0.9355054974524002 best_F: 0.9310298826040555 \n",
            "New best F1 score on validation set: 0.9355054974524002\n",
            "Saving Model to  ./End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/models/model_word_version\n",
            "New F1 on Train: 0.9832182888987399 - New F1 on Validation: 0.9355054974524002\n",
            "42000 :  tensor(0.0267, device='cuda:0')\n",
            "44000 :  tensor(0.0331, device='cuda:0')\n",
            "46000 :  tensor(0.0280, device='cuda:0')\n",
            "48000 :  tensor(0.0260, device='cuda:0')\n",
            "50000 :  tensor(0.0309, device='cuda:0')\n",
            "52000 :  tensor(0.0277, device='cuda:0')\n",
            "54000 :  tensor(0.0280, device='cuda:0')\n",
            "56000 :  tensor(0.0268, device='cuda:0')\n",
            "58000 :  tensor(0.0240, device='cuda:0')\n",
            "60000 :  tensor(0.0269, device='cuda:0')\n",
            "Train: new_F: 0.9873265319054559 best_F: 0.9832182888987399 \n",
            "Dev: new_F: 0.941113130089508 best_F: 0.9355054974524002 \n",
            "New best F1 score on validation set: 0.941113130089508\n",
            "Saving Model to  ./End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/models/model_word_version\n",
            "New F1 on Train: 0.9873265319054559 - New F1 on Validation: 0.941113130089508\n",
            "62000 :  tensor(0.0256, device='cuda:0')\n",
            "64000 :  tensor(0.0243, device='cuda:0')\n",
            "66000 :  tensor(0.0267, device='cuda:0')\n",
            "68000 :  tensor(0.0255, device='cuda:0')\n",
            "70000 :  tensor(0.0196, device='cuda:0')\n",
            "72000 :  tensor(0.0234, device='cuda:0')\n",
            "74000 :  tensor(0.0245, device='cuda:0')\n",
            "76000 :  tensor(0.0230, device='cuda:0')\n",
            "78000 :  tensor(0.0225, device='cuda:0')\n",
            "80000 :  tensor(0.0194, device='cuda:0')\n",
            "Train: new_F: 0.9904592855558021 best_F: 0.9873265319054559 \n",
            "Dev: new_F: 0.9371889710827168 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9904592855558021 - New F1 on Validation: 0.9371889710827168\n",
            "82000 :  tensor(0.0181, device='cuda:0')\n",
            "84000 :  tensor(0.0244, device='cuda:0')\n",
            "86000 :  tensor(0.0206, device='cuda:0')\n",
            "88000 :  tensor(0.0191, device='cuda:0')\n",
            "90000 :  tensor(0.0199, device='cuda:0')\n",
            "92000 :  tensor(0.0186, device='cuda:0')\n",
            "94000 :  tensor(0.0193, device='cuda:0')\n",
            "96000 :  tensor(0.0208, device='cuda:0')\n",
            "98000 :  tensor(0.0187, device='cuda:0')\n",
            "100000 :  tensor(0.0166, device='cuda:0')\n",
            "102000 :  tensor(0.0229, device='cuda:0')\n",
            "104000 :  tensor(0.0160, device='cuda:0')\n",
            "Train: new_F: 0.9917705893524086 best_F: 0.9904592855558021 \n",
            "Dev: new_F: 0.9387073056613863 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9917705893524086 - New F1 on Validation: 0.9387073056613863\n",
            "106000 :  tensor(0.0197, device='cuda:0')\n",
            "108000 :  tensor(0.0157, device='cuda:0')\n",
            "110000 :  tensor(0.0162, device='cuda:0')\n",
            "Train: new_F: 0.9935680111530052 best_F: 0.9917705893524086 \n",
            "Dev: new_F: 0.9378819421126855 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9935680111530052 - New F1 on Validation: 0.9378819421126855\n",
            "112000 :  tensor(0.0179, device='cuda:0')\n",
            "114000 :  tensor(0.0155, device='cuda:0')\n",
            "Train: new_F: 0.9937194696441033 best_F: 0.9935680111530052 \n",
            "Dev: new_F: 0.9394715556753842 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9937194696441033 - New F1 on Validation: 0.9394715556753842\n",
            "116000 :  tensor(0.0195, device='cuda:0')\n",
            "118000 :  tensor(0.0165, device='cuda:0')\n",
            "120000 :  tensor(0.0165, device='cuda:0')\n",
            "Train: new_F: 0.9941665081478663 best_F: 0.9937194696441033 \n",
            "Dev: new_F: 0.9363648594107359 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9941665081478663 - New F1 on Validation: 0.9363648594107359\n",
            "122000 :  tensor(0.0161, device='cuda:0')\n",
            "124000 :  tensor(0.0146, device='cuda:0')\n",
            "Train: new_F: 0.9947703717790244 best_F: 0.9941665081478663 \n",
            "Dev: new_F: 0.9379606056545625 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9947703717790244 - New F1 on Validation: 0.9379606056545625\n",
            "126000 :  tensor(0.0177, device='cuda:0')\n",
            "128000 :  tensor(0.0128, device='cuda:0')\n",
            "130000 :  tensor(0.0161, device='cuda:0')\n",
            "Train: new_F: 0.9949892173030572 best_F: 0.9947703717790244 \n",
            "Dev: new_F: 0.9361730717549046 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9949892173030572 - New F1 on Validation: 0.9361730717549046\n",
            "132000 :  tensor(0.0161, device='cuda:0')\n",
            "134000 :  tensor(0.0167, device='cuda:0')\n",
            "Train: new_F: 0.9954650683411029 best_F: 0.9949892173030572 \n",
            "Dev: new_F: 0.9362988845585271 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9954650683411029 - New F1 on Validation: 0.9362988845585271\n",
            "136000 :  tensor(0.0142, device='cuda:0')\n",
            "138000 :  tensor(0.0153, device='cuda:0')\n",
            "140000 :  tensor(0.0125, device='cuda:0')\n",
            "Train: new_F: 0.9950220362091379 best_F: 0.9954650683411029 \n",
            "Dev: new_F: 0.9396018294323379 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9950220362091379 - New F1 on Validation: 0.9396018294323379\n",
            "142000 :  tensor(0.0136, device='cuda:0')\n",
            "144000 :  tensor(0.0157, device='cuda:0')\n",
            "Train: new_F: 0.9950545270098909 best_F: 0.9954650683411029 \n",
            "Dev: new_F: 0.9361873990306948 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9950545270098909 - New F1 on Validation: 0.9361873990306948\n",
            "146000 :  tensor(0.0158, device='cuda:0')\n",
            "148000 :  tensor(0.0135, device='cuda:0')\n",
            "150000 :  tensor(0.0159, device='cuda:0')\n",
            "Train: new_F: 0.9959106038991916 best_F: 0.9954650683411029 \n",
            "Dev: new_F: 0.9365303244005643 best_F: 0.941113130089508 \n",
            "New F1 on Train: 0.9959106038991916 - New F1 on Validation: 0.9365303244005643\n",
            "3258.1770956516266\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASRFJREFUeJzt3XtcVGXiP/DPXJgZrgMIDBdRQFE0BQwUKc02J9Htot0W3XY1Ktu1m/3o6m5hu7WLmfl1LVc2W8suprVb7tYWZRSWhagoXvKKooAww0WZgQEGmDm/P5CxSVAG5jAwft6v13ml5zzn8DzCMp99bkciCIIAIiIiogFM6uoKEBEREV0OAwsRERENeAwsRERENOAxsBAREdGAx8BCREREAx4DCxEREQ14DCxEREQ04DGwEBER0YAnd3UFnMFqtaKyshK+vr6QSCSurg4RERH1gCAIaGhoQHh4OKTSS/ehuEVgqaysRGRkpKurQURERL1QXl6OoUOHXrKMWwQWX19fAB0N9vPzc3FtiIiIqCeMRiMiIyNtn+OX4haBpXMYyM/Pj4GFiIhokOnJdA5OuiUiIqIBj4GFiIiIBjwGFiIiIhrwGFiIiIhowGNgISIiogGPgYWIiIgGPAYWIiIiGvAYWIiIiGjAY2AhIiKiAY+BhYiIiAY8BhYiIiIa8BhYiIiIaMBzi5cfiqXdYsVfPjvc7fWk4QG4OT68H2tERER0ZWJguQSrALz5/alur79dcBrXjw6Bj5L/jERERGLiJ+0lSCXAQ78Y0eW1v+efgMUqoMnczsBCREQkMn7SXoJcJsWTaXFdXvvn9lK0tFnRarH2c62IiIiuPJx020seso5/utZ2BhYiIiKxMbD0klJ+PrCwh4WIiEh0vQosa9asQVRUFFQqFVJSUrBz584e3bdp0yZIJBLMmTPH7rwgCMjKykJYWBg8PT2h1Wpx/Pjx3lSt3yjO97C0tQsurgkREZH7cziwbN68GZmZmVi6dCn27NmDhIQEpKWlobq6+pL3nTp1Ck888QSmTp160bXly5dj9erVyMnJQWFhIby9vZGWloaWlhZHq9dvPGw9LBYX14SIiMj9ORxYVq5ciYULFyIjIwNjx45FTk4OvLy8sH79+m7vsVgsuPvuu/GnP/0JMTExdtcEQcCqVavw7LPPYvbs2YiPj8fbb7+NyspKbNmyxeEG9ZfOHhYz57AQERGJzqHA0traiqKiImi12gsPkEqh1WpRUFDQ7X1//vOfERISgvvuu++ia6WlpdDpdHbPVKvVSElJ6faZZrMZRqPR7uhvnZNu2ywcEiIiIhKbQ4GltrYWFosFGo3G7rxGo4FOp+vynu3bt+Of//wn1q1b1+X1zvsceWZ2djbUarXtiIyMdKQZTqGQc5UQERFRfxF1lVBDQwN++9vfYt26dQgKCnLac5csWQKDwWA7ysvLnfbsnuoMLG1cJURERCQ6hzaOCwoKgkwmg16vtzuv1+sRGhp6UfkTJ07g1KlTuOWWW2znrNaOD3i5XI6jR4/a7tPr9QgLC7N7ZmJiYpf1UCqVUCqVjlTd6RTch4WIiKjfONTDolAokJSUhLy8PNs5q9WKvLw8pKamXlQ+Li4OBw4cQHFxse249dZb8Ytf/ALFxcWIjIxEdHQ0QkND7Z5pNBpRWFjY5TMHCg4JERER9R+Ht+bPzMzEggULkJycjEmTJmHVqlUwmUzIyMgAAMyfPx8RERHIzs6GSqXCuHHj7O739/cHALvzjz32GF588UXExsYiOjoazz33HMLDwy/ar2UgsfWwcEiIiIhIdA4HlvT0dNTU1CArKws6nQ6JiYnIzc21TZotKyuDVOrY1JinnnoKJpMJDzzwAOrr6zFlyhTk5uZCpVI5Wr1+48EeFiIion4jEQRh0K/LNRqNUKvVMBgM8PPz65ev+fgH+/DvPRV4ZlYcfj+t6zc6ExERUfcc+fzmu4R6SSGXAADa2MNCREQkOgaWXuIcFiIiov7DwNJLCr6tmYiIqN8wsPSSB/dhISIi6jcMLL3EfViIiIj6DwNLL3FrfiIiov7DwNJL3JqfiIio/zCw9BIn3RIREfUfBpZeujDpdtDvu0dERDTgMbD0EvdhISIi6j8MLL1km3TLOSxERESiY2DpJQ/2sBAREfUbBpZeUnIfFiIion7DwNJL3IeFiIio/zCw9BK35iciIuo/DCy91NnDYmZgISIiEh0DSy95yCQAOCRERETUHxhYeknJnW6JiIj6DQNLLylkMgCcw0JERNQfGFh6yUPOISEiIqL+wsDSS51b87dZBFitfJ8QERGRmBhYeqlzlRAAtFnZy0JERCQmBpZe6tyHBeA8FiIiIrExsPSSgoGFiIio3zCw9JJUKoFc2jnxlnNYiIiIxMTA0gcKvgCRiIioXzCw9IEtsFgsLq4JERGRe2Ng6YMLL0DkkBAREZGYGFj6oHPiLbfnJyIiEhcDSx90vk+Iu90SERGJi4GlDy4MCTGwEBERialXgWXNmjWIioqCSqVCSkoKdu7c2W3Zjz76CMnJyfD394e3tzcSExPxzjvv2JW55557IJFI7I6ZM2f2pmr9iquEiIiI+ofc0Rs2b96MzMxM5OTkICUlBatWrUJaWhqOHj2KkJCQi8oHBgbij3/8I+Li4qBQKPDpp58iIyMDISEhSEtLs5WbOXMm3nzzTdvflUplL5vUfzxkHfuwcA4LERGRuBzuYVm5ciUWLlyIjIwMjB07Fjk5OfDy8sL69eu7LH/99dfjtttuw5gxYzBixAgsXrwY8fHx2L59u105pVKJ0NBQ2xEQENC7FvUj9rAQERH1D4cCS2trK4qKiqDVai88QCqFVqtFQUHBZe8XBAF5eXk4evQorrvuOrtr+fn5CAkJwejRo7Fo0SLU1dU5UjWXUMhlABhYiIiIxObQkFBtbS0sFgs0Go3deY1GgyNHjnR7n8FgQEREBMxmM2QyGf7+97/jxhtvtF2fOXMmbr/9dkRHR+PEiRP4wx/+gFmzZqGgoAAymeyi55nNZpjNZtvfjUajI81wGoWsc2t+BhYiIiIxOTyHpTd8fX1RXFyMxsZG5OXlITMzEzExMbj++usBAHPnzrWVHT9+POLj4zFixAjk5+dj+vTpFz0vOzsbf/rTn/qj6pd0YadbBhYiIiIxOTQkFBQUBJlMBr1eb3der9cjNDS0+y8ilWLkyJFITEzE448/jjvvvBPZ2dndlo+JiUFQUBBKSkq6vL5kyRIYDAbbUV5e7kgznEbBZc1ERET9wqHAolAokJSUhLy8PNs5q9WKvLw8pKam9vg5VqvVbkjn5yoqKlBXV4ewsLAuryuVSvj5+dkdruDBnW6JiIj6hcNDQpmZmViwYAGSk5MxadIkrFq1CiaTCRkZGQCA+fPnIyIiwtaDkp2djeTkZIwYMQJmsxmfffYZ3nnnHaxduxYA0NjYiD/96U+44447EBoaihMnTuCpp57CyJEj7ZY9D0RcJURERNQ/HA4s6enpqKmpQVZWFnQ6HRITE5Gbm2ubiFtWVgap9ELHjclkwoMPPoiKigp4enoiLi4O7777LtLT0wEAMpkM+/fvx4YNG1BfX4/w8HDMmDEDL7zwwoDfi6Wzh4WTbomIiMQlEQRh0L9q2Gg0Qq1Ww2Aw9OvwUPZnh/GPb09i4dRo/PGmsf32dYmIiNyBI5/ffJdQH3BIiIiIqH8wsPTBhUm3g76TioiIaEBjYOkD9rAQERH1DwaWPlBw0i0REVG/YGDpAw/2sBAREfULBpY+UHLjOCIion7BwNIHHnK+/JCIiKg/MLD0geL8m6TNHBIiIiISFQNLH3CVEBERUf9gYOkDDxmHhIiIiPoDA0sfsIeFiIiofzCw9IFSzn1YiIiI+gMDSx/YtuZnDwsREZGoGFj6wDYkxB4WIiIiUTGw9AF7WIiIiPoHA0sfKLjTLRERUb9gYOkDJVcJERER9QsGlj7oHBKyCoDFKri4NkRERO6LgaUPOifdAuxlISIiEhMDSx909rAADCxERERiYmDpg86t+QFOvCUiIhITA0sfSCQS7sVCRETUDxhY+qhzaXMbh4SIiIhEw8DSR+xhISIiEh8DSx8puNstERGR6BhY+shD3jHxlj0sRERE4mFg6SP2sBAREYmPgaWP+AJEIiIi8TGw9FHn+4TaOCREREQkGgaWPlLwBYhERESiY2DpI9uQEHtYiIiIRMPA0kfsYSEiIhJfrwLLmjVrEBUVBZVKhZSUFOzcubPbsh999BGSk5Ph7+8Pb29vJCYm4p133rErIwgCsrKyEBYWBk9PT2i1Whw/frw3Vet3CvawEBERic7hwLJ582ZkZmZi6dKl2LNnDxISEpCWlobq6uouywcGBuKPf/wjCgoKsH//fmRkZCAjIwNffPGFrczy5cuxevVq5OTkoLCwEN7e3khLS0NLS0vvW9ZPPOTcmp+IiEhsDgeWlStXYuHChcjIyMDYsWORk5MDLy8vrF+/vsvy119/PW677TaMGTMGI0aMwOLFixEfH4/t27cD6OhdWbVqFZ599lnMnj0b8fHxePvtt1FZWYktW7b0qXH9QckeFiIiItE5FFhaW1tRVFQErVZ74QFSKbRaLQoKCi57vyAIyMvLw9GjR3HdddcBAEpLS6HT6eyeqVarkZKS0u0zzWYzjEaj3eEq3IeFiIhIfA4FltraWlgsFmg0GrvzGo0GOp2u2/sMBgN8fHygUChw00034dVXX8WNN94IALb7HHlmdnY21Gq17YiMjHSkGU514eWHgsvqQERE5O76ZZWQr68viouLsWvXLvzlL39BZmYm8vPze/28JUuWwGAw2I7y8nLnVdZBXCVEREQkPrkjhYOCgiCTyaDX6+3O6/V6hIaGdnufVCrFyJEjAQCJiYk4fPgwsrOzcf3119vu0+v1CAsLs3tmYmJil89TKpVQKpWOVF00nUNC3OmWiIhIPA71sCgUCiQlJSEvL892zmq1Ii8vD6mpqT1+jtVqhdlsBgBER0cjNDTU7plGoxGFhYUOPdNV2MNCREQkPod6WAAgMzMTCxYsQHJyMiZNmoRVq1bBZDIhIyMDADB//nxEREQgOzsbQMd8k+TkZIwYMQJmsxmfffYZ3nnnHaxduxYAIJFI8Nhjj+HFF19EbGwsoqOj8dxzzyE8PBxz5sxxXktFomRgISIiEp3DgSU9PR01NTXIysqCTqdDYmIicnNzbZNmy8rKIJVe6LgxmUx48MEHUVFRAU9PT8TFxeHdd99Fenq6rcxTTz0Fk8mEBx54APX19ZgyZQpyc3OhUqmc0ERxecgkADgkREREJCaJIAiDfnmL0WiEWq2GwWCAn59fv37tt74vxfOfHMJN8WFY8+ur+/VrExERDWaOfH7zXUJ95MEhISIiItExsPSRgquEiIiIRMfA0kdcJURERCQ+BpY+Yg8LERGR+BhY+og9LEREROJjYOmjzsBiZmAhIiISDQNLH3FrfiIiIvExsPTRhbc1M7AQERGJhYGljzon3XIOCxERkXgYWPqos4elzTLoNwwmIiIasBhY+og9LEREROJjYOkjD85hISIiEh0DSx/9tIfFDd4jSURENCAxsPRR5xwWgPNYiIiIxMLA0kedPSwA92IhIiISCwNLH/20h4UTb4mIiMTBwNJHMqkEUknHnznxloiISBwMLE7AFyASERGJi4HFCWwrhdjDQkREJAoGFidgDwsREZG4GFicQME3NhMREYmKgcUJ2MNCREQkLgYWJ/DgHBYiIiJRMbA4AXtYiIiIxMXA4gQefGMzERGRqBhYnKCzh4XvEiIiIhIHA4sTKDuHhCwWF9eEiIjIPTGwOAGHhIiIiMTFwOIEF3a65ZAQERGRGBhYnICrhIiIiMTFwOIEHtzploiISFS9Cixr1qxBVFQUVCoVUlJSsHPnzm7Lrlu3DlOnTkVAQAACAgKg1WovKn/PPfdAIpHYHTNnzuxN1VyCPSxERETicjiwbN68GZmZmVi6dCn27NmDhIQEpKWlobq6usvy+fn5mDdvHr755hsUFBQgMjISM2bMwJkzZ+zKzZw5E1VVVbbj/fff712LXEAhkwBgYCEiIhKLw4Fl5cqVWLhwITIyMjB27Fjk5OTAy8sL69ev77L8e++9hwcffBCJiYmIi4vDG2+8AavViry8PLtySqUSoaGhtiMgIKB3LXKBC/uwMLAQERGJwaHA0traiqKiImi12gsPkEqh1WpRUFDQo2c0NTWhra0NgYGBdufz8/MREhKC0aNHY9GiRairq+v2GWazGUaj0e5wpc7AYmYPCxERkSgcCiy1tbWwWCzQaDR25zUaDXQ6XY+e8fTTTyM8PNwu9MycORNvv/028vLy8NJLL2Hbtm2YNWsWLN1sxJadnQ21Wm07IiMjHWmG0/Hlh0REROKS9+cXW7ZsGTZt2oT8/HyoVCrb+blz59r+PH78eMTHx2PEiBHIz8/H9OnTL3rOkiVLkJmZafu70Wh0aWixDQmxh4WIiEgUDvWwBAUFQSaTQa/X253X6/UIDQ295L0rVqzAsmXL8OWXXyI+Pv6SZWNiYhAUFISSkpIuryuVSvj5+dkdrqRgDwsREZGoHAosCoUCSUlJdhNmOyfQpqamdnvf8uXL8cILLyA3NxfJycmX/ToVFRWoq6tDWFiYI9VzGU66JSIiEpfDq4QyMzOxbt06bNiwAYcPH8aiRYtgMpmQkZEBAJg/fz6WLFliK//SSy/hueeew/r16xEVFQWdTgedTofGxkYAQGNjI5588kns2LEDp06dQl5eHmbPno2RI0ciLS3NSc0Ul4LvEiIiIhKVw3NY0tPTUVNTg6ysLOh0OiQmJiI3N9c2EbesrAxS6YUctHbtWrS2tuLOO++0e87SpUvx/PPPQyaTYf/+/diwYQPq6+sRHh6OGTNm4IUXXoBSqexj8/pH56RbrhIiIiISh0QQhEH/xj6j0Qi1Wg2DweCS+Syf7KvEI+/vxeSYQGx6oPuhMSIiIrrAkc9vvkvICbg1PxERkbgYWJyAq4SIiIjExcDiBBf2YRn0o2tEREQDEgOLE9iGhNjDQkREJAoGFifw4LJmIiIiUTGwOAHnsBAREYmLgcUJFHIJAPawEBERiYWBxQkUMhkAbs1PREQkFgYWJ+A+LEREROJiYHECD1nHkFC7VYDVyqXNREREzsbA4gSdPSwAJ94SERGJgYHFCRhYiIiIxMXA4gQeP3k7dRvnsRARETkdA4sTSKUS2zwW9rAQERE5HwOLk3C3WyIiIvEwsDiJ7QWI7GEhIiJyOgYWJ+ncnt/MHhYiIiKnY2BxEg4JERERiYeBxUmUtiEhbhxHRETkbAwsTsLt+YmIiMTDwOIktiEhi8XFNSEiInI/DCxOcqGHhUNCREREzsbA4iTcOI6IiEg8DCxOopDLAHBrfiIiIjEwsDiJwjaHhYGFiIjI2RhYnEQhPz8kxB4WIiIip2NgcZLOHhZuzU9EROR8DCxO0rlKiFvzExEROR8Di5Nwa34iIiLxMLA4Cd/WTEREJB4GFidRsIeFiIhINL0KLGvWrEFUVBRUKhVSUlKwc+fObsuuW7cOU6dORUBAAAICAqDVai8qLwgCsrKyEBYWBk9PT2i1Whw/frw3VXMZ9rAQERGJx+HAsnnzZmRmZmLp0qXYs2cPEhISkJaWhurq6i7L5+fnY968efjmm29QUFCAyMhIzJgxA2fOnLGVWb58OVavXo2cnBwUFhbC29sbaWlpaGlp6X3L+hn3YSEiIhKPRBAEh15+k5KSgokTJ+K1114DAFitVkRGRuKRRx7BM888c9n7LRYLAgIC8Nprr2H+/PkQBAHh4eF4/PHH8cQTTwAADAYDNBoN3nrrLcydO/eyzzQajVCr1TAYDPDz83OkOU6Ts+0Eln1+BLdfHYGVv0p0SR2IiIgGE0c+vx3qYWltbUVRURG0Wu2FB0il0Gq1KCgo6NEzmpqa0NbWhsDAQABAaWkpdDqd3TPVajVSUlK6fabZbIbRaLQ7XO3CPix8+SEREZGzORRYamtrYbFYoNFo7M5rNBrodLoePePpp59GeHi4LaB03ufIM7Ozs6FWq21HZGSkI80QxYW3NVtcXBMiIiL306+rhJYtW4ZNmzbh448/hkql6vVzlixZAoPBYDvKy8udWMve4SohIiIi8cgdKRwUFASZTAa9Xm93Xq/XIzQ09JL3rlixAsuWLcNXX32F+Ph42/nO+/R6PcLCwuyemZiY2OWzlEollEqlI1UX3YVVQhwSIiIicjaHelgUCgWSkpKQl5dnO2e1WpGXl4fU1NRu71u+fDleeOEF5ObmIjk52e5adHQ0QkND7Z5pNBpRWFh4yWcONNzploiISDwO9bAAQGZmJhYsWIDk5GRMmjQJq1atgslkQkZGBgBg/vz5iIiIQHZ2NgDgpZdeQlZWFjZu3IioqCjbvBQfHx/4+PhAIpHgsccew4svvojY2FhER0fjueeeQ3h4OObMmeO8lorMNoeFy5qJiIiczuHAkp6ejpqaGmRlZUGn0yExMRG5ubm2SbNlZWWQSi903Kxduxatra2488477Z6zdOlSPP/88wCAp556CiaTCQ888ADq6+sxZcoU5Obm9mmeS3+7MOmWgYWIiMjZHN6HZSAaCPuw/HCiFr9eV4iRIT74KnOaS+pAREQ0mIi2Dwt1T8mt+YmIiETDwOIkCpkMAIeEiIiIxMDA4iQecgkABhYiIiIxMLA4CV9+SEREJB4GFifhPixERETiYWBxEk66JSIiEg8Di5N07sNiFYB2hhYiIiKnYmBxks4hIYDzWIiIiJyNgcVJOntYAKCtfdDvxUdERDSgMLA4iVwqgaRjZTPMFotrK0NERORmGFicRCKRcKUQERGRSBhYnEgp61wpxCEhIiIiZ2JgcSIPvrGZiIhIFAwsTqTgkBAREZEoGFicqHOlEJc1ExERORcDixN5yPgCRCIiIjEwsDiRQi4DwO35iYiInI2BxYkUnHRLREQkCgYWJ1J0Dgmxh4WIiMipGFicSME3NhMREYmCgcWJOne6NXNIiIiIyKkYWJyI+7AQERGJg4HFiTgkREREJA4GFidiDwsREZE4GFiciD0sRERE4mBgcSLuw0JERCQOBhYnsq0SYg8LERGRUzGwOJFtSKhdcHFNiIiI3AsDixN19rC0WiwurgkREZF7YWBxIiXnsBAREYmCgcWJOpc1t1k4JERERORMvQosa9asQVRUFFQqFVJSUrBz585uy/7444+44447EBUVBYlEglWrVl1U5vnnn4dEIrE74uLielM1l/LofPkhe1iIiIicyuHAsnnzZmRmZmLp0qXYs2cPEhISkJaWhurq6i7LNzU1ISYmBsuWLUNoaGi3z73qqqtQVVVlO7Zv3+5o1VxOIZcB4NuaiYiInM3hwLJy5UosXLgQGRkZGDt2LHJycuDl5YX169d3WX7ixIl4+eWXMXfuXCiVym6fK5fLERoaajuCgoIcrZrLcR8WIiIicTgUWFpbW1FUVAStVnvhAVIptFotCgoK+lSR48ePIzw8HDExMbj77rtRVlbWbVmz2Qyj0Wh3DAQcEiIiIhKHQ4GltrYWFosFGo3G7rxGo4FOp+t1JVJSUvDWW28hNzcXa9euRWlpKaZOnYqGhoYuy2dnZ0OtVtuOyMjIXn9tZ1Jya34iIiJRDIhVQrNmzcJdd92F+Ph4pKWl4bPPPkN9fT0++OCDLssvWbIEBoPBdpSXl/dzjbt2YR8WBhYiIiJnkjtSOCgoCDKZDHq93u68Xq+/5IRaR/n7+2PUqFEoKSnp8rpSqbzkfBhX4RwWIiIicTjUw6JQKJCUlIS8vDzbOavViry8PKSmpjqtUo2NjThx4gTCwsKc9sz+oGAPCxERkSgc6mEBgMzMTCxYsADJycmYNGkSVq1aBZPJhIyMDADA/PnzERERgezsbAAdE3UPHTpk+/OZM2dQXFwMHx8fjBw5EgDwxBNP4JZbbsHw4cNRWVmJpUuXQiaTYd68ec5qZ7/wYA8LERGRKBwOLOnp6aipqUFWVhZ0Oh0SExORm5trm4hbVlYGqfRCx01lZSUmTJhg+/uKFSuwYsUKTJs2Dfn5+QCAiooKzJs3D3V1dQgODsaUKVOwY8cOBAcH97F5/evCTrcMLERERM4kEQRh0O8jbzQaoVarYTAY4Ofn57J6HNc34Mb/+xYBXh7YmzXDZfUgIiIaDBz5/B4Qq4TchW2VEIeEiIiInIqBxYkUcr78kIiISAwMLE70031Y3GCkjYiIaMBgYHGizh4WgEubiYiInImBxYmUPwksHBYiIiJyHgYWJ+ocEgKA5laLC2tCRETkXhhYnEgmlSAy0BMAcEzf9YsbiYiIyHEMLE4WP9QfAFBcXu/SehAREbkTBhYnSzwfWPYxsBARETkNA4uTJUT6AwD2VdS7tB5ERETuhIHFycZF+EEqAfRGM3SGFldXh4iIyC0wsDiZl0KOURpfAOxlISIichYGFhEkdg4LcR4LERGRUzCwiIDzWIiIiJyLgUUECedXCu0vN8Bq5Y63REREfcXAIoJRGh+oPKRoMLfjZK3J1dUhIiIa9BhYRCCXSTE+Qg2A81iIiIicgYFFJJ3DQpzHQkRE1HcMLCJJ4EohIiIip2FgEUnn0uZDVUaY2/nmZiIior5gYBHJ0ABPBHor0GYRcLiKb24mIiLqCwYWkUgkEiQM5cRbIiIiZ2BgERHnsRARETkHA4uIOgNLMVcKERER9QkDi4g6lzafrDHB0Nzm2soQERENYgwsIgr0VmBYoBcA4ECFwcW1ISIiGrwYWETGFyESERH1HQOLyDpXChVz4i0REVGvMbCIjCuFiIiI+o6BRWRXhftBJpWgusEMnaHF1dUhIiIalBhYROalkGOUxhcAh4WIiIh6q1eBZc2aNYiKioJKpUJKSgp27tzZbdkff/wRd9xxB6KioiCRSLBq1ao+P3OwSYw8v+MtJ94SERH1isOBZfPmzcjMzMTSpUuxZ88eJCQkIC0tDdXV1V2Wb2pqQkxMDJYtW4bQ0FCnPHOw6dyPhfNYiIiIesfhwLJy5UosXLgQGRkZGDt2LHJycuDl5YX169d3WX7ixIl4+eWXMXfuXCiVSqc8c7DpnHi7v8IAq1VwbWWIiIgGIYcCS2trK4qKiqDVai88QCqFVqtFQUFBryogxjMHmtgQH/go5Wg0t2P/GW4gR0RE5CiHAkttbS0sFgs0Go3deY1GA51O16sK9OaZZrMZRqPR7hjI5DIprhsVBADIO6x3cW2IiIgGn0G5Sig7Oxtqtdp2REZGurpKl6Ud0xHIth5iYCEiInKUQ4ElKCgIMpkMer39h65er+92Qq0Yz1yyZAkMBoPtKC8v79XX7k+/GB0CmVSCI7oGlJ9tcnV1iIiIBhWHAotCoUBSUhLy8vJs56xWK/Ly8pCamtqrCvTmmUqlEn5+fnbHQBfgrUDy8AAAHBYiIiJylMNDQpmZmVi3bh02bNiAw4cPY9GiRTCZTMjIyAAAzJ8/H0uWLLGVb21tRXFxMYqLi9Ha2oozZ86guLgYJSUlPX6mu7hxbMew0FeH3WO5NhERUX+RO3pDeno6ampqkJWVBZ1Oh8TEROTm5tomzZaVlUEqvZCDKisrMWHCBNvfV6xYgRUrVmDatGnIz8/v0TPdxfQxGrz4v8PYcbIOhuY2qD09XF0lIiKiQUEiCMKg3xjEaDRCrVbDYDAM+OEh7cptKKluxOp5E3BrQrirq0NEROQyjnx+D8pVQoNZ52qhr7haiIiIqMcYWPrZjWNDAADfHK1Gm8Xq4toQERENDgws/SwxMgBDvBVoaGnHrtKzrq4OERHRoMDA0s9kUgmmj+noZdnK5c1EREQ9wsDiArZ5LIf1cIM5z0RERKJjYHGBKbFBUMqlKD/bjKP6BldXh4iIaMBjYHEBL4UcU0Z2vAyRq4WIiIguj4HFRbTnd73dyl1viYiILouBxUWmx3VMvN1XXo9qY4uLa0NERDSwMbC4SIifCgmR/gCAvCPsZSEiIroUBhYXmjGWu94SERH1BAOLC3Uub/6upBZfH2FoISIi6g4DiwuN0vggJToQre1W3PvWbvzh4wMwmdtdXS0iIqIBh4HFhSQSCTbcOwn3T4kGAGwsLMNNq7/DnrJzLq4ZERHRwMLA4mIqDxmevXksNt6fgjC1CqfqmnDn2h/wypdH+XJEIiKi8xhYBohrRgYh97HrcNuECFgF4NWvSzD39R0wt1tcXTUiIiKXY2AZQNSeHvi/9ES89usJ8FXJUXT6HP5bXOnqahEREbkcA8sAdHN8OB68fiQA4I3vSvmCRCIiuuIxsAxQv04ZBm+FDEf1Dfj2eK2rq0NERORSDCwDlNrTA7+aGAkAeOO7ky6uDRERkWsxsAxg914bDakE+O54LQ5XGV1dHSIiIpdhYBnAIgO9MGt8GABgHXtZiIjoCsbAMsA9MDUGAPDJvkroDHyrMxERXZkYWAa4hEh/TIoKRJtFwFs/nHJ1dYiIiFyCgWUQWHhdRy/LxsLTaOziXUM6QwseeHs35r5eAENzW39Xj4iISHQMLIPA9LgQxAR5w9jSjg92ldtdyzusx6y/fYsvD+mx4+RZvPjpIRfVkoiISDwMLIOAVCrBfVM7XpC4/vtStFusMLdb8Px/f8R9G3bjXFMbRob4QCIBPiyqQP7RahfXmIiIyLkYWAaJO64eikBvBSrONeMf357EbWt+sM1puffaaPzv0Sm455ooAMCSjw7A2MKhISIich8MLIOEykOG30weDgB4+YujOFRlRKC3AuvvSUbWLWOhlMvwZNpoDB/ihSpDC7I/O+ziGhMRETkPA8sgMj91OJTyjm9ZaswQfL54Km6I09iueynkWH5HPADg/Z3l+PZYjUvqSURE5GwMLINIkI8S792fgr/NTcS796dA46e6qExKzBAsSO3oiVny0YEuVxURERENNgwsg0xyVCBmJ0ZAJpV0W+apmXGIDPTEmfpmDg0REZFb6FVgWbNmDaKioqBSqZCSkoKdO3desvyHH36IuLg4qFQqjB8/Hp999pnd9XvuuQcSicTumDlzZm+qRgC8lXK8dH5o6L3CMvxQwrc9ExHR4OZwYNm8eTMyMzOxdOlS7NmzBwkJCUhLS0N1dddLaX/44QfMmzcP9913H/bu3Ys5c+Zgzpw5OHjwoF25mTNnoqqqyna8//77vWsRAQCuGRGE30weBgB48l/7UVpruuw9LW0WvJR7BE/9ax9a2ixiV5GIiKjHJIIgCI7ckJKSgokTJ+K1114DAFitVkRGRuKRRx7BM888c1H59PR0mEwmfPrpp7ZzkydPRmJiInJycgB09LDU19djy5YtvWqE0WiEWq2GwWCAn59fr57hjhrN7Zj1t29RfrYZ3goZ/nr7eMxOjOiybEl1Ax7euBdHdA0AgCWz4vC7aSMu+zXqm1pR39SGqCBvp9adiIjcnyOf3w71sLS2tqKoqAharfbCA6RSaLVaFBQUdHlPQUGBXXkASEtLu6h8fn4+QkJCMHr0aCxatAh1dXXd1sNsNsNoNNoddDEfpRwf/u4aTIoOhKnVgsWbivHMv/ejufVC74kgCNi8qww3v7odR3QNUHl0/Ej8Pf/EZbf5b2mz4Pa//4Ab/28bDlQYRG0LERFd2RwKLLW1tbBYLNBoNHbnNRoNdDpdl/fodLrLlp85cybefvtt5OXl4aWXXsK2bdswa9YsWCxdD0tkZ2dDrVbbjsjISEeacUUJVauw8f4UPHrDSEgkwKZd5Ziz5nuUVDfA2NKGRzcV4+l/H0BLmxVTY4Ow7clfIDbEB4bmNrz+7YlLPnvNNyU4WWtCm0XAy18e7acWERHRlWhArBKaO3cubr31VowfPx5z5szBp59+il27diE/P7/L8kuWLIHBYLAd5eXlXZajDnKZFJkzRuOde1MQ5KPEUX0Dbnn1e8xa9R0+2VcJmVSCp2fGYUPGJGj8VHgybTQAYP32U6g2tnT5zJLqRuRs6wg0Egnw7bEaFJ7svleMiIioLxwKLEFBQZDJZNDr9Xbn9Xo9QkNDu7wnNDTUofIAEBMTg6CgIJSUlHR5XalUws/Pz+6gy5sSG4TPFk/BtSOHoLnNgjP1zYjw98QHv0vFoutHQHp+qfSNYzWYMMwfzW0WvPr1xd8DQRDw3JaDaLMI+MXoYPx6Usfk3hVfHoWDU6KIiIh6xKHAolAokJSUhLy8PNs5q9WKvLw8pKamdnlPamqqXXkA2Lp1a7flAaCiogJ1dXUICwtzpHrUAyG+Krx9bwqybh6L+6ZE47PFU5E0PMCujETS0eMCAO/vLMPpOvsVRluKz6DgZB2Ucin+PHscHrkhFkq5FLtOncM27q5LREQicHhIKDMzE+vWrcOGDRtw+PBhLFq0CCaTCRkZGQCA+fPnY8mSJbbyixcvRm5uLl555RUcOXIEzz//PHbv3o2HH34YANDY2Ignn3wSO3bswKlTp5CXl4fZs2dj5MiRSEtLc1Iz6adkUgnunRKN524eC7WnR5dlJscMwbRRwWi3Cli59ZjtvKGpDX/5X8dmdI9Oj0VkoBdC1SrMP7+7LntZiIhIDA4HlvT0dKxYsQJZWVlITExEcXExcnNzbRNry8rKUFVVZSt/zTXXYOPGjXj99deRkJCAf/3rX9iyZQvGjRsHAJDJZNi/fz9uvfVWjBo1Cvfddx+SkpLw3XffQalUOqmZ1Budc1n+U1yJHys7VgG9/OUR1Da2YkSwNxZOjbGVXXT9SHgrZDh4xojcg11PwO7EQENERI5yeB+WgYj7sIjnkff34pN9lfjF6GAs1o7CbX//HoIAvL9wMlJHDLEru/LLo1j9dQlGhvjgi8euu+j1AeVnm/DEh/twosaEv942DjOu6n4eExERuT/R9mGhK8/jN46CXCrBN0drsOjdIggCcPuEiIvCCgDcf10M1J4eKKluxJa9Z+yubdl7Br/823coLD2L2kYzHninCC9+eghtFqtT65t7sAp/+uRH1De1OvW5RETkWgwsdElRQd5In9ixz02VoQV+Kjn+cNOYLsv6qTzw+/O7467KO4bWdiuMLW14bNNePLa5GA3mdiQND8A910QBAN7YXor0fxSgsr7ZKXX9YFc5fv/uHrz5/Sn8el0hzpoYWoiI3AUDC13Wo9NjbTvgPj0rDkE+3c8tWnDNcAT5KFF+thkv/u8Qfvm377CluBJSCfCYNhabH5iM52+9Cv/4bRJ8VXLsKavHL1d/h2+OdP0uqp76d1EFnv5oPwBAIZfiUJURc18vQE2DuU/PJSKigYFzWKhHvj1WgxM1jViQGmXbr6U7b31fiuc/OWT7e2SgJ1alJyJpeKBdufKzTXho4x7sP7+t/69ThmFEsA+8FDJ4KWTw9JDBSyFHqFqFkSE+3X69/xSfwWObiyEIwG8nD8eCa6Jw9xs7oDeaERPsjY33T0aoWtXlvaW1JlQZmpEaMwQSyaXbRUREzuXI5zcDCzmdud2CGf/3LU7XNeG2CRH48+yr4Kvqevm0ud2Cv/7vMDYUnL7kMydGBeC+KdG4cWyo3WTeT/ZVYvGmvbAKwLxJw/CXOeMglUpwus6EX68rxJn6Zgwf4oWNCycjwt8TAGCxCsg7rMc7O07ju+O1AIBnbxqD+3+y6omIiMTHwEIuV9Nght7YgnER6h6Vzzusx9ZDephaLWhubUdTqwVNrRY0t1pwoqYR7daOH9PIQE9kXBONX02MxHfHavDw+3thsQr4VfJQLLs93q73p+JcE+at24Hysx07+q65+2r8cKIW7+0ow5mfzZuRSyXY9MBkJEfZ9wIREZF4GFjIreiNLXi74BTeKyxDfVPHG6R9lXI0t1nQbhVwx9VD8fKd8V0OVVUZmvHrdYUorbXfrTfAywO/mhiJ36QMx/IvjuKTfZUI9VPh00endDtHx2IVsDz3CPKP1uCpmaMxfYymy3JERNQzDCzklppbLfj3ngqs/74UJ2s6AsicxHC88qvEi/Z8+alqYwvufqMQx6sbkTBUjd+mRuHm+DCoPGQAgEZzO2a/th0nakyYMjIIG+6ddNHzWtoseGxTMXJ/vLAp3vzU4fjDL8fYnuMIQRDQ3GaBl0Lu8L1ERO6CgYXcmtUqYNvxGugNLbgzaSjksssvdmtps6DK0ILoIO8urx/TN2D2a9+juc2CR6fHIvPGUbZrhuY2LHx7N3aWnoVCJsWNV2nwv/0duzmP0vhg9bwJiAvt+c9dWV0TnvjXPuw+dRYzxobi/qnRSBoewEm/RHTFYWAh6oX/FJ/B4k3FkEiAN++ZiOtHh6DK0Ix71u/CUX0DfJVyvD4/GakjhmDbsRo8/sE+1DaaoZBLsWRWHO65JuqSoUMQBLy/sxwv/u8QmlotdtcSIv1x35RozBoXCo8eBDAiInfAwELUS89uOYB3d5TB38sDq9ITseSjA6gytCDEV4kN907CmLALP191jWY89a/9yDu/h8zU2CDMnTgM144cAn8vhd1z9cYWPP3v/cg/2vE260lRgXh0eiz+d6AS/95zBq3tHTv+hqtVuDNpKJQeMpjbLGhpt3b8t63jenSwN2JDfBAb4ouhAZ6XXWJORDSQMbAQ9ZK53YK7cgpse8MAQEywN96+dxKGBnhdVF4QBLyz4zT+8r/DMJ8PHRIJEB+hxtTYYEyJDYLe2IKs//wIQ3MbFHIpnpwxGvdOibbNk6ltNOO9HWV4Z8cp1Db2fHdelYcUI4J9EBfqh1sSwjA1NviSc3lqG83YvKsce8vOYVigN8aE+WJsuB9GhvhAKe/5PBxzuwXfl9Rif4UB4f6eGBHsg5HBPlB7db10nYioOwwsRH1QfrYJN7+6HYbmNlw9zB//XDARAd6KS95TUt2IjYVl2F5Sg2P6xi7LjIvww8pfJWKUxrfL6y1tFvy3uBI7TtZBLpNA5SGDUi61/bfNIuBkrQnH9Q04WWuy9cp0ivD3xK+SI3FX8lCEn99zRhAE7Cw9i3cLy5B7sAptlov/5y6XSjAyxAdjwvwQF+qL0aG+GBPmhxBfpW2Iq6XNgm3HapB7UIevDunRYG6/6DlBPkqMCPbGmDA//G5aDMLUnpf8NyMiYmAh6qMjOiN+KKnDvEnD4KlwbBWQztCC7SW1+O54DbYfr0WDuR2/nzYCj9ww0mnzU9otVpSfa0ZJdSO+L6nFx3vPwNDcseRbKgGmjQpGclQgtuw9g+PVFwJUQqQ/bhofisr6FhyuMuJwlRHGlovDBwD4e3kgLtQXfioPbC+ptZt3E+KrxLUjg1DTYMaJmkZUGVrs7g32VeKN+clIiPTvcZvOmVpxsrYRJ6pNOFHTiOoGM0aG+CBhqD/GD1VD7Sl+D05prQnvFJzGjWM1Xb7gk4ici4GFaICwWgVYBaFHK5n6oqXNgtyDOmzaVYYdJ8/aXfP0kGHOhHDcnTL8oo38BEFApaEFhyo7wstRXQOO6IworTXB+rPfDOFqFWaND8OscaG4eliA3fyZRnM7TtY0oqS6Ef/YdhJH9Q1QyqV45VcJuDk+vMs6W6wCtuw9g827y1FS3XjZl1XGBHsjcag/xkWoMcRHAT+VB3xUcviq5PBVecDf0wPeyt4vEy86fQ73bdhl2+vn+tHBeCotDmPDB//vFItVwO5TZzEuQt2nfyMiZ2NgIbqCldaasGlXGY5UNeCGuBDcdnUE/Lp5NUJ3WtosKKluxBFdA2oazEgdMQQJQ9U9Wnrd0NKGxZuK8fX5yciZN47CIzeMtN0rCAK+OlyNl784ctHwWZhahRHBPhgR7I1gXyWO6huxr7weZWebelTv60cH495rozE1NsihZeJbD+nxyPt70NJmxbBAL1TWN6PdKkAiAeYkRiDzxlGIDLx4DtNg0NJmweJNe/HFj3rEhvjgvftTEOLX9bu1iPobAwsRuZTFKuCvnx3GP7eXAgBmJ4bjpTvisa+8Hi/lHsGesnoAgJ9Kjt9NG4Fpo4IRHeTd7f/7P2tqxb6Keuwrr8eRqgYYmtvQYG5DY0s7Gs4frZYLc3pGhvgg49oo3D5h6GWH9DYWluHZLQdgFYBfjA7GmruvRrXRjFe2HsMn+yoBAAqZFHdPHoab48MxNszP4WFCR1mtAk7UNGJveT2O6xswOtQPN8SFIPAyc6l+rr6pFfdt2I2i0+ds56KDvLFxYQrnGNGAwMBCRAPCxsIyZP3nINqtAoJ9lahpMAPoWOF077XR+N11I5y2uuhUrQkbCk7hg13lMJ2fb+Pv5YH0iZGYFhuMq8LVdl9LEAT831fHsTrvOADgV8lD8dfbxtsN3x2oMOCl3CPYXlJrOyeTShD7k7k1Y8J8YTJboDe2oPr8O7R0hhbUN7VhaIAn4sJ8z09o9kOwr/1rHyxWAXUmM6qNZlTWN+PAGQP2lnUEs59PbJZKgKuHBUA7VgPtmBCMCPa5ZC9SxbkmLFi/EydqTPBVyfHn2VdhxRfHcKa+GZGBnth4/+Rue41Kqhvw4e4KpMQE4hejQ/ptU8Om1nZ8dbga4WoVN1O8QjCwENGA8UNJLRa9tweG5jbIpRLMnRSJR2+IFW1YwtjShg93V2DDD6cuGkoaGuCJceFqXBXuh9I6Ez7acwYA8Oj0WPw/bWy3H5DfHa/Bhh9Oo7i8HrWN5l7XLchHgRHBPmhqtaC6oQW1ja2w/Hyy0HmeHjKMH6pGbIgP9pTV43CV0e561BAv3BCnwfQxIZgYFQiF/ELQ+rHSgIw3d6G6wYwwtQpvZUzC6FBfVJxrwt1vFOJ0XRMi/D3x3v0piPrJ7s9ldU1YlXcMW/aesc1hmhwTiD/8cgzih/o73F5BEFDdYEagt+KSE84tVgH/LqrAii+Povp8qB0T5of5qcMxOzGcr7BwYwwsRDSgnK4z4dP9VbhpfJjdB6SYLFYBeYf12FJ8BgfPGLucByOVAC/MGYe7U4b36JmCIEBvNGNfRT0OVBiw/4wBx/UN8FN5QKNWQeOrhMZPBY2fEn6eHiira8IRXQMOVxlRWmdCV79tJRJgiLcSGj8lxoT5YcIwfyRG+mO0xteut6fiXBO+PlKNrw5XY8eJOrshMB+lHNeNCsINcRr4KOV44sN9aDS3Y7TGF2/dO9Fu+EdnaMGv39iBkzUmaPyUeO/+yfBSyPDq1yX4cHe57c3ok6ICUVxRb1s+f2tCOJ5MG33JuTyCIKCkuhE7Ss+i8GQddpaeRXWDGf5eHph5VShujg/H5JhAu3ZtP16LF/93CEd0DQA65jGdNbXa9jXyU8lxV3Ikfjt5uCg/O2dNrXh/Zxn+vacCCUP9kXXz2MtuY+Aoq1VAQ0s7fFTyS+6VdCViYCEi+hlDUxt+rDLgUKURB88YUGdqRca1Ubghrn/eut3casExfQNKazuGaEJ8VQjxU2KIt8LhVWSN5nZsP16DvMPV+OZodZcbDk6OCcQ/fpvc5XLwmgYzfvNGIY7qG6D29EBzq8UWgKaNCkbmjaOQEOmPM/XNeOWLo/hob0dPlEImxfzU4bgqwg+GpjYYW9phbG6DobkNZ02t2Ftef9nVXkE+CswaF4YpsUHYtLMM35zf/dlPJccjN8Ri/jXD0dxqwYe7K/DOjtN2QdNbIUPnB9ZPP7m8FDKoPT3g6+kBP5Ucak8P+Hl6IHqIN+KHqnFVhBo+P5sfdfCMARt+OIX/7Ku029MoyEeJZbePh3Zs9z8Xp2pNeH9XGerO/7tL0BE8O/4sQYO5DXWNrTjX1Iqzplaca2qDxSogyEeBX44Pw60J4RettBOD1SrgiK4B1Q0taLMIaLdY0Wqxot0ioN1qRWSgFyZFBV725++cqRW5P+pQ12jGwzfEOrWODCxERFcIq1XAgTMG5B2pxtdH9Dh4xohbE8Lx8l3xl9zB+KypFb95oxCHzg81pUQH4om00ZgYFXhR2YNnDMj+/DC+L6m7bH1UHlIkDQ/ApKghSIkJxPgINfaV1+OT/ZX4/KDOtmy8k1wqwW8mD8fi6bEX9WxYrQK2HavB2wWnkH+spsseqp6QSIARwT6Ij1BjpMYH+UdqsPPUheX/4yPUuP3qCGwsLLPtW3RX0lA8d8tYuxV2+yvqkbPtBD4/qOt1XTpF+Hvi5vgw3JIQDrWnB07WmnCyphEnahpxssaE03VNiAz0RPrESMwaF9bjt8I3tbZj+/FafH2kGl8fqbYNsXVniLcCaeNCcdP4MKREXwgvjeZ2bD2kwyf7qvDtsRq0WwWoPKQoevZGpy6NZ2AhIrpCNbdaeryKydDUhrcLTmHCsABcO3LIZV/eue1YDd78/hQsVgF+nhd6MvxUHlB7emBMmB/GR6jt5tP8VJvFiu9LavHJvioUnKhF/FB/PDVzNGKCfS5b17pGM0zmjsnUP6+mqbUdxuYLvT3GljacM7XiqL4B+ysMF21sCHQEpVnjw3DPNVG4epg/JBIJWtosWLn1GNZ9dxKC0LH30PI7E2ARBOTkn0DByQuB7RejgzEpumNzQQGCLcAIggBvpRyB3goM8VZ2/Pf8vkE7Suvwyb5KfPmjHo1d7BbdHT+VHLdNiMDcScPs3mdmsQqoONeEkzUmlFQ3YntJLQpO1tn1GHkrZIgK8oaHTAqFTAq5TAK5TAqpBCgur7cLkEO8FZhxlQaG5jbkHa62DcsBwNgwP9ySEI67Jw9zeJuES2FgISIiOq+6oQUHzxiwv8KAo7oGxIb44O7Jw6HpZuL3rlNn8fgH+y6a9ySXSnBrQjgemBaDuNDef9a0tFnwzZFq/HdfJfKOVEMQBAwf4o0Rwd6ICfbBiGAfDAv0QuHJOmzeXY6Kc822exMi/RHmp8LJ2kacqm2ym8vUKTLQE9PPT8ieFB3YbU9bm8WKghN1+OxAFb74UYdzP+v9ignyxi0J4bglIQwjQ7p+pUhfMbAQERH1gcncjmWfH8E7O07DSyHD3InDcN/UaET4O3f/mtZ2K6QSdDuPxGoV8P2JWmzaWY4vD+kueh+YQi5F9BBvxAR7IyHSH9PjQjAy5NJL3rvSZrFix8k6fHVID0+FHDfHh+GqcD/Rl5YzsBARETlBaa0Jgd6KfnmX1eXUNprx+YGOl5jGBHtjRLAPwv09B/XKI0c+v7m4nYiIqBvR/bQMvyeCfJT4bWqUq6vhMuK+kY2IiIjICRhYiIiIaMBjYCEiIqIBj4GFiIiIBrxeBZY1a9YgKioKKpUKKSkp2Llz5yXLf/jhh4iLi4NKpcL48ePx2Wef2V0XBAFZWVkICwuDp6cntFotjh8/3puqERERkRtyOLBs3rwZmZmZWLp0Kfbs2YOEhASkpaWhurq6y/I//PAD5s2bh/vuuw979+7FnDlzMGfOHBw8eNBWZvny5Vi9ejVycnJQWFgIb29vpKWloaXl4t0JiYiI6Mrj8D4sKSkpmDhxIl577TUAgNVqRWRkJB555BE888wzF5VPT0+HyWTCp59+ajs3efJkJCYmIicnB4IgIDw8HI8//jieeOIJAIDBYIBGo8Fbb72FuXPnXrZO3IeFiIho8HHk89uhHpbW1lYUFRVBq9VeeIBUCq1Wi4KCgi7vKSgosCsPAGlpabbypaWl0Ol0dmXUajVSUlK6fabZbIbRaLQ7iIiIyH05FFhqa2thsVig0di/dluj0UCn03V5j06nu2T5zv868szs7Gyo1WrbERkZ6UgziIiIaJAZlKuElixZAoPBYDvKy8tdXSUiIiISkUOBJSgoCDKZDHq93u68Xq9HaGhol/eEhoZesnznfx15plKphJ+fn91BRERE7suhwKJQKJCUlIS8vDzbOavViry8PKSmpnZ5T2pqql15ANi6dautfHR0NEJDQ+3KGI1GFBYWdvtMIiIiurI4/PLDzMxMLFiwAMnJyZg0aRJWrVoFk8mEjIwMAMD8+fMRERGB7OxsAMDixYsxbdo0vPLKK7jpppuwadMm7N69G6+//joAQCKR4LHHHsOLL76I2NhYREdH47nnnkN4eDjmzJnjvJYSERHRoOVwYElPT0dNTQ2ysrKg0+mQmJiI3Nxc26TZsrIySKUXOm6uueYabNy4Ec8++yz+8Ic/IDY2Flu2bMG4ceNsZZ566imYTCY88MADqK+vx5QpU5CbmwuVStWjOnWuzOZqISIiosGj83O7JzusOLwPy0BUUVHBlUJERESDVHl5OYYOHXrJMm4RWKxWKyorK+Hr6wuJROLUZxuNRkRGRqK8vPyKmNzL9rq3K629wJXXZrbXvblbewVBQENDA8LDw+1GZ7ri8JDQQCSVSi+bzPrqSluNxPa6tyutvcCV12a21725U3vVanWPyg3KfViIiIjoysLAQkRERAMeA8tlKJVKLF26FEql0tVV6Rdsr3u70toLXHltZnvd25XW3p9yi0m3RERE5N7Yw0JEREQDHgMLERERDXgMLERERDTgMbAQERHRgMfAchlr1qxBVFQUVCoVUlJSsHPnTldXySm+/fZb3HLLLQgPD4dEIsGWLVvsrguCgKysLISFhcHT0xNarRbHjx93TWWdIDs7GxMnToSvry9CQkIwZ84cHD161K5MS0sLHnroIQwZMgQ+Pj644447oNfrXVTjvlm7di3i4+Ntm0ulpqbi888/t113p7b+3LJly2wvVe3kbu19/vnnIZFI7I64uDjbdXdrLwCcOXMGv/nNbzBkyBB4enpi/Pjx2L17t+26O/3OioqKuuj7K5FI8NBDDwFwz+9vTzCwXMLmzZuRmZmJpUuXYs+ePUhISEBaWhqqq6tdXbU+M5lMSEhIwJo1a7q8vnz5cqxevRo5OTkoLCyEt7c30tLS0NLS0s81dY5t27bhoYcewo4dO7B161a0tbVhxowZMJlMtjL/7//9P3zyySf48MMPsW3bNlRWVuL22293Ya17b+jQoVi2bBmKioqwe/du3HDDDZg9ezZ+/PFHAO7V1p/atWsX/vGPfyA+Pt7uvDu296qrrkJVVZXt2L59u+2au7X33LlzuPbaa+Hh4YHPP/8chw4dwiuvvIKAgABbGXf6nbVr1y677+3WrVsBAHfddRcA9/v+9phA3Zo0aZLw0EMP2f5usViE8PBwITs724W1cj4Awscff2z7u9VqFUJDQ4WXX37Zdq6+vl5QKpXC+++/74IaOl91dbUAQNi2bZsgCB3t8/DwED788ENbmcOHDwsAhIKCAldV06kCAgKEN954w23b2tDQIMTGxgpbt24Vpk2bJixevFgQBPf83i5dulRISEjo8po7tvfpp58WpkyZ0u11d/+dtXjxYmHEiBGC1Wp1y+9vT7GHpRutra0oKiqCVqu1nZNKpdBqtSgoKHBhzcRXWloKnU5n13a1Wo2UlBS3abvBYAAABAYGAgCKiorQ1tZm1+a4uDgMGzZs0LfZYrFg06ZNMJlMSE1Nddu2PvTQQ7jpppvs2gW47/f2+PHjCA8PR0xMDO6++26UlZUBcM/2/ve//0VycjLuuusuhISEYMKECVi3bp3tujv/zmptbcW7776Le++9FxKJxC2/vz3FwNKN2tpaWCwWaDQau/MajQY6nc5Fteofne1z17ZbrVY89thjuPbaazFu3DgAHW1WKBTw9/e3KzuY23zgwAH4+PhAqVTi97//PT7++GOMHTvWLdu6adMm7NmzB9nZ2Rddc8f2pqSk4K233kJubi7Wrl2L0tJSTJ06FQ0NDW7Z3pMnT2Lt2rWIjY3FF198gUWLFuHRRx/Fhg0bALj376wtW7agvr4e99xzDwD3/HnuKbd4WzORIx566CEcPHjQbszfHY0ePRrFxcUwGAz417/+hQULFmDbtm2urpbTlZeXY/Hixdi6dStUKpWrq9MvZs2aZftzfHw8UlJSMHz4cHzwwQfw9PR0Yc3EYbVakZycjL/+9a8AgAkTJuDgwYPIycnBggULXFw7cf3zn//ErFmzEB4e7uqquBx7WLoRFBQEmUx20cxrvV6P0NBQF9Wqf3S2zx3b/vDDD+PTTz/FN998g6FDh9rOh4aGorW1FfX19XblB3ObFQoFRo4ciaSkJGRnZyMhIQF/+9vf3K6tRUVFqK6uxtVXXw25XA65XI5t27Zh9erVkMvl0Gg0btXervj7+2PUqFEoKSlxu+8vAISFhWHs2LF258aMGWMbBnPX31mnT5/GV199hfvvv992zh2/vz3FwNINhUKBpKQk5OXl2c5ZrVbk5eUhNTXVhTUTX3R0NEJDQ+3abjQaUVhYOGjbLggCHn74YXz88cf4+uuvER0dbXc9KSkJHh4edm0+evQoysrKBm2bf85qtcJsNrtdW6dPn44DBw6guLjYdiQnJ+Puu++2/dmd2tuVxsZGnDhxAmFhYW73/QWAa6+99qJtCI4dO4bhw4cDcM/fWQDw5ptvIiQkBDfddJPtnDt+f3vM1bN+B7JNmzYJSqVSeOutt4RDhw4JDzzwgODv7y/odDpXV63PGhoahL179wp79+4VAAgrV64U9u7dK5w+fVoQBEFYtmyZ4O/vL/znP/8R9u/fL8yePVuIjo4WmpubXVzz3lm0aJGgVquF/Px8oaqqynY0NTXZyvz+978Xhg0bJnz99dfC7t27hdTUVCE1NdWFte69Z555Rti2bZtQWloq7N+/X3jmmWcEiUQifPnll4IguFdbu/LTVUKC4H7tffzxx4X8/HyhtLRU+P777wWtVisEBQUJ1dXVgiC4X3t37twpyOVy4S9/+Ytw/Phx4b333hO8vLyEd99911bG3X5nWSwWYdiwYcLTTz990TV3+/72FAPLZbz66qvCsGHDBIVCIUyaNEnYsWOHq6vkFN98840A4KJjwYIFgiB0LBN87rnnBI1GIyiVSmH69OnC0aNHXVvpPuiqrQCEN99801amublZePDBB4WAgADBy8tLuO2224SqqirXVboP7r33XmH48OGCQqEQgoODhenTp9vCiiC4V1u78vPA4m7tTU9PF8LCwgSFQiFEREQI6enpQklJie26u7VXEAThk08+EcaNGycolUohLi5OeP311+2uu9vvrC+++EIA0GUb3PH72xMSQRAEl3TtEBEREfUQ57AQERHRgMfAQkRERAMeAwsRERENeAwsRERENOAxsBAREdGAx8BCREREAx4DCxEREQ14DCxEREQ04DGwEBER0YDHwEJEREQDHgMLERERDXgMLERERDTg/X+udL8rdaxB3QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "parameters['reload'] = False\n",
        "\n",
        "if not parameters['reload']:\n",
        "    tr = time.time()\n",
        "    model.train(True)\n",
        "    for epoch in range(1, number_of_epochs + 1):\n",
        "        for i, index in enumerate(np.random.permutation(len(train_data))):\n",
        "            count += 1\n",
        "            data = train_data[index]\n",
        "\n",
        "            ##gradient updates for each data entry\n",
        "            model.zero_grad()\n",
        "\n",
        "            sentence_in = data['words']\n",
        "            sentence_in = Variable(torch.LongTensor(sentence_in))\n",
        "            tags = data['tags']\n",
        "            chars2 = data['chars']\n",
        "\n",
        "            # if parameters['char_mode'] == 'LSTM':\n",
        "            #     chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n",
        "            #     d = {}\n",
        "            #     for i, ci in enumerate(chars2):\n",
        "            #         for j, cj in enumerate(chars2_sorted):\n",
        "            #             if ci == cj and not j in d and not i in d.values():\n",
        "            #                 d[j] = i\n",
        "            #                 continue\n",
        "            #     chars2_length = [len(c) for c in chars2_sorted]\n",
        "            #     char_maxl = max(chars2_length)\n",
        "            #     chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n",
        "            #     for i, c in enumerate(chars2_sorted):\n",
        "            #         chars2_mask[i, :chars2_length[i]] = c\n",
        "            #     chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
        "\n",
        "            if parameters['char_mode'] == 'CNN':\n",
        "                d = {}\n",
        "                ## Padding the each word to max word size of that sentence\n",
        "                chars2_length = [len(c) for c in chars2]\n",
        "                char_maxl = max(chars2_length)\n",
        "                chars2_mask = np.zeros((len(chars2_length), char_maxl), dtype='int')\n",
        "                for i, c in enumerate(chars2):\n",
        "                    chars2_mask[i, :chars2_length[i]] = c\n",
        "                chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
        "\n",
        "\n",
        "            targets = torch.LongTensor(tags)\n",
        "\n",
        "            #we calculate the negative log-likelihood for the predicted tags using the predefined function\n",
        "            if use_gpu:\n",
        "                neg_log_likelihood = model.neg_log_likelihood(sentence_in.cuda(), targets.cuda(), chars2_mask.cuda(), chars2_length)\n",
        "            else:\n",
        "                neg_log_likelihood = model.neg_log_likelihood(sentence_in, targets, chars2_mask, chars2_length)\n",
        "            loss += neg_log_likelihood.data / len(data['words'])\n",
        "            neg_log_likelihood.backward()\n",
        "\n",
        "            #we use gradient clipping to avoid exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm(model.parameters(), gradient_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "            #Storing loss\n",
        "            if count % plot_every == 0:\n",
        "                loss /= plot_every\n",
        "                print(count, ': ', loss)\n",
        "                if losses == []:\n",
        "                    losses.append(loss)\n",
        "                losses.append(loss)\n",
        "                loss = 0.0\n",
        "\n",
        "            #Evaluating on Train, Test, Dev Sets\n",
        "            if count % (eval_every) == 0 and count > (eval_every * 20) or \\\n",
        "                    count % (eval_every*4) == 0 and count < (eval_every * 20):\n",
        "                model.train(False)\n",
        "                best_train_F, new_train_F, _ = evaluating(model, train_data, best_train_F,\"Train\")\n",
        "                best_dev_F, new_dev_F, save = evaluating(model, dev_data, best_dev_F,\"Dev\")\n",
        "                if save:\n",
        "                    print(f\"New best F1 score on validation set: {best_dev_F}\")\n",
        "                    print(\"Saving Model to \", model_name)\n",
        "                    torch.save(model.state_dict(), model_name)\n",
        "                # best_test_F, new_test_F, _ = evaluating(model, test_data, best_test_F,\"Test\")\n",
        "\n",
        "                # all_F.append([new_train_F, new_dev_F, new_test_F])\n",
        "                print(f\"New F1 on Train: {new_train_F} - New F1 on Validation: {new_dev_F}\")\n",
        "                model.train(True)\n",
        "\n",
        "            #Performing decay on the learning rate\n",
        "            if count % len(train_data) == 0:\n",
        "                adjust_learning_rate(optimizer, lr=learning_rate/(1+decay_rate*count/len(train_data)))\n",
        "\n",
        "    print(time.time() - tr)\n",
        "    losses_cpu = [loss_tensor.cpu().detach().numpy() for loss_tensor in losses]\n",
        "    plt.plot(losses_cpu)\n",
        "    plt.show()\n",
        "\n",
        "if not parameters['reload']:\n",
        "    #reload the best model saved from training\n",
        "    model.load_state_dict(torch.load(model_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haZ-loNW-d3m"
      },
      "source": [
        "# Model Testing\n",
        "\n",
        "This is where the model will be tested after training and evaluating process."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First we need to load the best model which was saved during the training and evaluating process"
      ],
      "metadata": {
        "id": "kWK8Y4BqSruj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ztRaj5xXdqG"
      },
      "outputs": [],
      "source": [
        "def LoadModel(modelPath):\n",
        "  if not os.path.exists(parameters['reload']):\n",
        "    print(\"Path lỗi, không load được.\")\n",
        "    return None\n",
        "  loadModel = BiLSTM_CRF(vocab_size=len(word_to_id),\n",
        "                   tag_to_ix=tag_to_id,\n",
        "                   embedding_dim=parameters['word_dim'],\n",
        "                   hidden_dim=parameters['word_lstm_dim'],\n",
        "                   use_gpu=use_gpu,\n",
        "                   char_to_ix=char_to_id,\n",
        "                   pre_word_embeds=word_embeds,\n",
        "                   use_crf=parameters['crf'],\n",
        "                   char_mode=parameters['char_mode'],\n",
        "                   char_out_dimension = 50)\n",
        "  loadModel.load_state_dict(torch.load(modelPath))\n",
        "  print(\"model reloaded :\", modelPath)\n",
        "  if use_gpu:\n",
        "    loadModel.cuda()\n",
        "  return loadModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we test the model"
      ],
      "metadata": {
        "id": "_tcB-6IkS1tb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vWtulRx-d3m"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content/drive/MyDrive/NLP project\n",
        "\n",
        "# Predict ở đây nha\n",
        "# điền dữ liệu test vào dòng MakeSentences ở dưới này\n",
        "path = './End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/models/model_word_version'\n",
        "model = LoadModel(path)\n",
        "another_txt = \"\"\n",
        "\n",
        "for data in test_data:\n",
        "    words = data['str_words']\n",
        "    chars2 = data['chars']\n",
        "\n",
        "    # Padding the each word to max word size of that sentence\n",
        "    chars2_length = [len(c) for c in chars2]\n",
        "    char_maxl = max(chars2_length)\n",
        "    chars2_mask = np.zeros((len(chars2_length), char_maxl), dtype='int')\n",
        "    for i, c in enumerate(chars2):\n",
        "        chars2_mask[i, :chars2_length[i]] = c\n",
        "    chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
        "\n",
        "    dwords = Variable(torch.LongTensor(data['words']))\n",
        "\n",
        "    # We are getting the predicted output from our model\n",
        "    if use_gpu:\n",
        "        val,predicted_id = model(dwords.cuda(), chars2_mask.cuda(), chars2_length)\n",
        "    else:\n",
        "        val,predicted_id = model(dwords, chars2_mask, chars2_length)\n",
        "\n",
        "    print('Predicted id: ', predicted_id)\n",
        "    print('Words: ', words)\n",
        "\n",
        "    # Group\n",
        "    another_list_tags = ['NA'] * len(words)\n",
        "\n",
        "    for index, tag in enumerate(predicted_id):\n",
        "        for iob in tag_to_id:\n",
        "            if tag_to_id[iob] == tag:\n",
        "              another_list_tags[index] = iob\n",
        "              break\n",
        "\n",
        "    for word, tag in zip(words, another_list_tags):\n",
        "        another_txt += word + ' ' + tag + '\\n'\n",
        "\n",
        "    another_txt += '\\n'\n",
        "\n",
        "# Group:\n",
        "with open('./End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/evaluation/prediction_CnnBLSTMCrf_IOB.txt', 'w') as another_f:\n",
        "  another_f.write(another_txt)\n",
        "print(\"\\nPrediction complete!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Draw the confusion matrix\n",
        "- We first need to load the predicted data.\n",
        "- Based on the predicted and ground-truth data, we will draw the confusion matrix"
      ],
      "metadata": {
        "id": "y6Xl8Umu81TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to read the labels\n",
        "def get_labels(file_path):\n",
        "  all_labels = []\n",
        "  current_sentence = []\n",
        "\n",
        "  file_format = (file_path.split('/')[-1]).split('.')[1]\n",
        "\n",
        "  if file_format == 'conll':\n",
        "    for line in codecs.open(file_path, 'r', 'utf-8'):\n",
        "      line = line.strip()\n",
        "\n",
        "      if not line:\n",
        "        if len(current_sentence) != 0:\n",
        "          all_labels.append(current_sentence)\n",
        "          current_sentence = []\n",
        "      else:\n",
        "        # We only need the label therefore\n",
        "        word, label = line.split()\n",
        "        current_sentence.append(label)\n",
        "    if len(current_sentence) != 0:\n",
        "      all_labels.append(current_sentence)\n",
        "\n",
        "  else:\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "      for line in f:\n",
        "        line = line.strip()\n",
        "\n",
        "        if not line:\n",
        "          if(len(current_sentence) != 0):\n",
        "            all_labels.append(current_sentence)\n",
        "            current_sentence = []\n",
        "        else:\n",
        "          word, label = line.split()\n",
        "          current_sentence.append(label)\n",
        "\n",
        "      if len(current_sentence) != 0:\n",
        "        all_labels.append(current_sentence)\n",
        "\n",
        "  return all_labels"
      ],
      "metadata": {
        "id": "ElceeEtJ80Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = get_labels(parameters['test'])\n",
        "y_pred = get_labels(r'./End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/evaluation/prediction_CnnBLSTMCrf_IOB.txt')\n",
        "\n",
        "# print(y_true)\n",
        "# print(y_pred)\n",
        "\n",
        "print(f'Accuracy score: {accuracy_score(y_true, y_pred):.2f}')\n",
        "print(f'Precision score: {precision_score(y_true, y_pred):.2f}')\n",
        "print(f'Recall score: {recall_score(y_true, y_pred):.2f}')\n",
        "print(f'F1 score: {f1_score(y_true, y_pred):.2f}')\n",
        "print(f'\\nDetailed report:\\n{classification_report(y_true, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt9II3xABAKD",
        "outputId": "c76a3670-b8d0-4aed-d711-6e929213dc79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.96\n",
            "Precision score: 0.92\n",
            "Recall score: 0.89\n",
            "F1 score: 0.91\n",
            "\n",
            "Detailed report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                AGE       0.95      0.93      0.94       582\n",
            "               DATE       0.97      0.97      0.97      1654\n",
            "             GENDER       0.93      0.93      0.93       462\n",
            "                JOB       0.66      0.50      0.57       173\n",
            "           LOCATION       0.91      0.91      0.91      4441\n",
            "               NAME       0.93      0.71      0.81       318\n",
            "       ORGANIZATION       0.84      0.77      0.80       771\n",
            "         PATIENT_ID       0.97      0.96      0.96      2005\n",
            "SYMPTOM_AND_DISEASE       0.86      0.76      0.80      1136\n",
            "     TRANSPORTATION       0.92      0.85      0.88       193\n",
            "\n",
            "          micro avg       0.92      0.89      0.91     11735\n",
            "          macro avg       0.89      0.83      0.86     11735\n",
            "       weighted avg       0.92      0.89      0.90     11735\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRuf1GfGBiaf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}