{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install conllu\n",
        "!pip install transformers datasets seqeval\n",
        "!pip install hf_xet\n",
        "!pip install pyvi\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KVCtBb-e77Iq",
        "outputId": "348c08a9-ebbe-4366-d341-6b6c7f93ad16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading conllu-6.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-6.0.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=7b730c158d4f6f3087d671d0581c39de706a8d3bec75198d4f922cf9c3ae8512\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Requirement already satisfied: hf_xet in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pyvi) (1.6.1)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (3.6.0)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (4.67.1)\n",
            "Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.11 pyvi-0.1.1 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWmZszO_NTvf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/VinAIResearch/PhoNER_COVID19.git\n",
        "!git clone https://github.com/J4Fsake/NLP_NER_BERT.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thực hiện analyze từng câu để biết được có bao nhiêu câu và số câu có độ dài lớn hơn max length (128).**"
      ],
      "metadata": {
        "id": "GDhCmPgC7_Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/NLP_NER_BERT')\n",
        "\n",
        "import MyUtils\n",
        "\n",
        "print('File train_word.conll')\n",
        "MyUtils.analyze_sentence_lengths('/content/PhoNER_COVID19/data/word/train_word.conll')\n",
        "print('--------------------')\n",
        "print('File dev_word.conll')\n",
        "MyUtils.analyze_sentence_lengths('/content/PhoNER_COVID19/data/word/dev_word.conll')\n",
        "print('--------------------')\n",
        "print('File test_word.conll')\n",
        "MyUtils.analyze_sentence_lengths('/content/PhoNER_COVID19/data/word/test_word.conll')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS_VsM8Q8Cd5",
        "outputId": "af2f2293-3188-46c4-d4ae-540cbef24724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File train_word.conll\n",
            "Tổng số câu: 5027\n",
            "Độ dài 161 có 1 câu\n",
            "--------------------\n",
            "File dev_word.conll\n",
            "Tổng số câu: 2000\n",
            "Độ dài 138 có 1 câu\n",
            "--------------------\n",
            "File test_word.conll\n",
            "Tổng số câu: 3000\n",
            "Độ dài 138 có 1 câu\n",
            "Độ dài 139 có 1 câu\n",
            "Độ dài 162 có 1 câu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Đọc và xử lý từng câu trong file, đối với những câu có độ dài lớn hơn max length (128) thì sẽ thực hiện chèn khoảng trắng (\"\\n\") để chia đôi câu đó ra.**"
      ],
      "metadata": {
        "id": "tO-JpFEy8F0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing\n",
        "!python /content/NLP_NER_BERT/preprocess.py /content/PhoNER_COVID19/data/word/train_word.conll vinai/phobert-large 128 > train.txt\n",
        "!python /content/NLP_NER_BERT/preprocess.py /content/PhoNER_COVID19/data/word/dev_word.conll vinai/phobert-large 128 > dev.txt\n",
        "!python /content/NLP_NER_BERT/preprocess.py /content/PhoNER_COVID19/data/word/test_word.conll vinai/phobert-large 128 > test.txt\n",
        "!cat train.txt dev.txt test.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels.txt"
      ],
      "metadata": {
        "id": "Kep5o_LCN_yA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491b335c-40ea-43d2-d376-15963a26e620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json: 100% 558/558 [00:00<00:00, 3.86MB/s]\n",
            "vocab.txt: 100% 895k/895k [00:00<00:00, 4.73MB/s]\n",
            "bpe.codes: 100% 1.14M/1.14M [00:00<00:00, 57.4MB/s]\n",
            "tokenizer.json: 100% 3.13M/3.13M [00:00<00:00, 12.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thực hiện analyze lại các file đã được preprocess, ta sẽ thấy được các câu có độ dài lớn hơn max length (128) đã bị cắt ra.**"
      ],
      "metadata": {
        "id": "S4_zNcwz8Lvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MyUtils.analyze_sentence_lengths('train.txt')\n",
        "MyUtils.analyze_sentence_lengths('dev.txt')\n",
        "MyUtils.analyze_sentence_lengths('test.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDwCF8YA8Nv6",
        "outputId": "0c87fdd6-a110-47e0-da8a-29d7e212ddf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tổng số câu: 5029\n",
            "Tổng số câu: 2003\n",
            "Tổng số câu: 3008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning PhoBERT và sau load model pretrained và bắt đầu train.**"
      ],
      "metadata": {
        "id": "qM4SJAu-8fQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Arguments\n",
        "BERT_MODEL = \"vinai/phobert-large\"\n",
        "CONFIG_NAME = \"\"\n",
        "TASK_TYPE = \"NER\"\n",
        "TOKENIZER_NAME = \"\"\n",
        "USE_FAST = False\n",
        "CACHE_DIR = \"\"\n",
        "\n",
        "# Data Training Arguments\n",
        "DATA_DIR = \"/content\"\n",
        "LABELS = \"/content/labels.txt\"\n",
        "MAX_LENGTH = 128\n",
        "OVERWRITE_CACHE = \"\"\n",
        "\n",
        "# Training Arguments\n",
        "OUTPUT_DIR = \"/content/pho_bert_large/lr5e-5_bs16\"\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 5e-5\n",
        "WEIGHT_DECAY = 0.0\n",
        "NUM_EPOCHS = 1\n",
        "SAVE_STEPS = 750\n",
        "SEED = 42\n",
        "SAVE_TOTAL_LIMIT = 5\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "!python /content/NLP_NER_BERT/run_ner.py \\\n",
        "  --model_name_or_path $BERT_MODEL \\\n",
        "  --task_type $TASK_TYPE \\\n",
        "  --data_dir $DATA_DIR \\\n",
        "  --labels $LABELS \\\n",
        "  --max_seq_length $MAX_LENGTH \\\n",
        "  --output_dir $OUTPUT_DIR \\\n",
        "  --overwrite_output_dir \\\n",
        "  --learning_rate $LEARNING_RATE \\\n",
        "  --weight_decay $WEIGHT_DECAY \\\n",
        "  --num_train_epochs $NUM_EPOCHS \\\n",
        "  --per_device_train_batch_size $BATCH_SIZE \\\n",
        "  --per_device_eval_batch_size $BATCH_SIZE \\\n",
        "  --save_total_limit $SAVE_TOTAL_LIMIT \\\n",
        "  --save_steps $SAVE_STEPS \\\n",
        "  --seed $SEED \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_predict"
      ],
      "metadata": {
        "id": "yEN6qoRDOksZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9b09c4-8692-4a67-e825-d2ad5bafe815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-05 05:51:23.583579: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749102683.616138    2072 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749102683.626308    2072 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-05 05:51:23.657143: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/pho_bert_large/lr5e-5_bs16/runs/Jun05_05-51-36_4b1cb53e0a16,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/pho_bert_large/lr5e-5_bs16,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=16,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/pho_bert_large/lr5e-5_bs16,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=750,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=5,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:698] 2025-06-05 05:51:36,443 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-large/snapshots/1c7880f20db59c0054c6de5afd71b012369f6ee4/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-05 05:51:36,449 >> Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-AGE\",\n",
            "    \"1\": \"B-DATE\",\n",
            "    \"2\": \"B-GENDER\",\n",
            "    \"3\": \"B-JOB\",\n",
            "    \"4\": \"B-LOCATION\",\n",
            "    \"5\": \"B-NAME\",\n",
            "    \"6\": \"B-ORGANIZATION\",\n",
            "    \"7\": \"B-PATIENT_ID\",\n",
            "    \"8\": \"B-SYMPTOM_AND_DISEASE\",\n",
            "    \"9\": \"B-TRANSPORTATION\",\n",
            "    \"10\": \"I-AGE\",\n",
            "    \"11\": \"I-DATE\",\n",
            "    \"12\": \"I-JOB\",\n",
            "    \"13\": \"I-LOCATION\",\n",
            "    \"14\": \"I-NAME\",\n",
            "    \"15\": \"I-ORGANIZATION\",\n",
            "    \"16\": \"I-PATIENT_ID\",\n",
            "    \"17\": \"I-SYMPTOM_AND_DISEASE\",\n",
            "    \"18\": \"I-TRANSPORTATION\",\n",
            "    \"19\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"B-AGE\": 0,\n",
            "    \"B-DATE\": 1,\n",
            "    \"B-GENDER\": 2,\n",
            "    \"B-JOB\": 3,\n",
            "    \"B-LOCATION\": 4,\n",
            "    \"B-NAME\": 5,\n",
            "    \"B-ORGANIZATION\": 6,\n",
            "    \"B-PATIENT_ID\": 7,\n",
            "    \"B-SYMPTOM_AND_DISEASE\": 8,\n",
            "    \"B-TRANSPORTATION\": 9,\n",
            "    \"I-AGE\": 10,\n",
            "    \"I-DATE\": 11,\n",
            "    \"I-JOB\": 12,\n",
            "    \"I-LOCATION\": 13,\n",
            "    \"I-NAME\": 14,\n",
            "    \"I-ORGANIZATION\": 15,\n",
            "    \"I-PATIENT_ID\": 16,\n",
            "    \"I-SYMPTOM_AND_DISEASE\": 17,\n",
            "    \"I-TRANSPORTATION\": 18,\n",
            "    \"O\": 19\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 258,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"PhobertTokenizer\",\n",
            "  \"transformers_version\": \"4.52.3\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64001\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:799] 2025-06-05 05:51:36,533 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:698] 2025-06-05 05:51:36,614 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-large/snapshots/1c7880f20db59c0054c6de5afd71b012369f6ee4/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-05 05:51:36,614 >> Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 258,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"PhobertTokenizer\",\n",
            "  \"transformers_version\": \"4.52.3\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64001\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-05 05:51:36,873 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--phobert-large/snapshots/1c7880f20db59c0054c6de5afd71b012369f6ee4/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-05 05:51:36,873 >> loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--phobert-large/snapshots/1c7880f20db59c0054c6de5afd71b012369f6ee4/bpe.codes\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-05 05:51:36,873 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-05 05:51:36,873 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-05 05:51:36,873 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-05 05:51:36,874 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-large/snapshots/1c7880f20db59c0054c6de5afd71b012369f6ee4/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-05 05:51:36,874 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|configuration_utils.py:698] 2025-06-05 05:51:36,874 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--phobert-large/snapshots/1c7880f20db59c0054c6de5afd71b012369f6ee4/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-05 05:51:36,875 >> Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 258,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"PhobertTokenizer\",\n",
            "  \"transformers_version\": \"4.52.3\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64001\n",
            "}\n",
            "\n",
            "pytorch_model.bin: 100% 1.48G/1.48G [00:07<00:00, 198MB/s]\n",
            "[INFO|modeling_utils.py:1150] 2025-06-05 05:51:45,580 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--phobert-large/snapshots/1c7880f20db59c0054c6de5afd71b012369f6ee4/pytorch_model.bin\n",
            "[INFO|safetensors_conversion.py:61] 2025-06-05 05:51:46,155 >> Attempting to create safetensors variant\n",
            "[INFO|safetensors_conversion.py:74] 2025-06-05 05:51:47,414 >> Safetensors PR exists\n",
            "[INFO|modeling_utils.py:5120] 2025-06-05 05:51:47,522 >> Some weights of the model checkpoint at vinai/phobert-large were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:5132] 2025-06-05 05:51:47,522 >> Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at vinai/phobert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:utils_ner:Creating features from dataset file at /content\n",
            "INFO:utils_ner:Writing example 0 of 5029\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: train-1\n",
            "INFO:utils_ner:tokens: <s> Đồng_thời , bệnh_viện tiếp_tục thực_hiện các biện_pháp phòng_chống dịch_bệnh CO@@ VI@@ D - 19 theo hướng_dẫn của Bộ Y_tế . </s>\n",
            "INFO:utils_ner:input_ids: 0 1248 4 757 194 112 9 717 2137 3795 9089 6232 1927 31 1195 63 1010 7 125 1059 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 19 19 19 19 19 19 19 19 -100 -100 19 19 19 19 19 6 15 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: train-2\n",
            "INFO:utils_ner:tokens: <s> \" Số bệnh_viện có_thể tiếp_nhận bệnh_nhân bị sốt cao và khó thở đang giảm dần \" , thông_cáo có đoạn , cảnh_báo những bệnh_nhân này thay vào đó được chuyển tới các phòng_khám khẩn_cấp , khiến những bệnh_nhân mắc bệnh hiểm_nghèo khác không có cơ_hội được điều_trị . </s>\n",
            "INFO:utils_ner:input_ids: 0 22 1907 757 62 1665 798 45 2122 84 6 359 2194 52 197 976 22 4 7886 10 687 4 1223 21 798 23 1016 33 37 11 430 75 9 5990 2498 4 122 21 798 1021 326 12299 85 17 10 521 11 782 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 19 19 19 19 19 8 17 19 8 17 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: train-3\n",
            "INFO:utils_ner:tokens: <s> Ngoài_ra , những người tiếp_xúc gián_tiếp ( đã gặp những người tiếp_xúc gần với bệnh_nhân ) được lập danh_sách và yêu_cầu cách_ly y_tế tại nơi ở . </s>\n",
            "INFO:utils_ner:input_ids: 0 492 4 21 18 1963 7475 20 14 243 21 18 1963 124 15 798 19 11 740 1092 6 285 8677 973 35 189 25 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: train-4\n",
            "INFO:utils_ner:tokens: <s> Bà này khi trở về quá_cảnh Doha ( Qatar ) , đáp xuống Tân_Sơn_Nhất sáng 2/3 cùng 75 hành_khách , trong đó có 55 người nước_ngoài . </s>\n",
            "INFO:utils_ner:input_ids: 0 680 23 26 682 28 15687 17387 20 4382 19 4 2509 307 5211 298 7431 81 3255 1442 4 12 37 10 2999 18 516 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 19 19 19 19 4 19 4 19 19 19 19 4 19 1 19 19 19 19 19 19 19 19 19 19 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: train-5\n",
            "INFO:utils_ner:tokens: <s> \" Bệnh_nhân 523 \" và chồng là \" bệnh_nhân 522 \" , 67 tuổi , được Bộ Y_tế ghi_nhận nhiễm n@@ CoV hôm 31/7 . </s>\n",
            "INFO:utils_ner:input_ids: 0 22 6207 50335 22 6 327 8 22 798 49562 22 4 4151 126 4 11 125 1059 1334 2002 1301 58339 654 16554 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 7 19 19 19 19 19 19 7 19 19 0 19 19 19 6 15 19 19 19 -100 19 1 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "model.safetensors:   5% 73.4M/1.48G [00:00<00:13, 106MB/s] INFO:utils_ner:Saving features into cached file /content/cached_train_PhobertTokenizer_128\n",
            "INFO:utils_ner:Creating features from dataset file at /content\n",
            "INFO:utils_ner:Writing example 0 of 2003\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: dev-1\n",
            "INFO:utils_ner:tokens: <s> Bác_sĩ Nguyễn_Trung_@@ Nguyên , Giám_đốc Trung_tâm Chống độc , Bệnh_viện Bạch_Mai , cho biết bệnh_nhân được chuyển đến bệnh_viện ngày 7/3 , chẩn_đoán ngộ_độc thuốc điều_trị sốt_rét chloro@@ qu@@ ine . </s>\n",
            "INFO:utils_ner:input_ids: 0 3608 13087 1759 4 693 664 6894 1964 4 1089 6671 4 13 55 798 11 430 30 757 43 19742 4 3807 3928 529 782 14093 37848 2845 3403 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 -100 19 19 6 15 15 15 15 15 19 19 19 19 19 19 19 19 19 1 19 19 8 17 19 19 19 -100 -100 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: dev-2\n",
            "INFO:utils_ner:tokens: <s> \" Bệnh_nhân 812 \" , nam , 62 tuổi , là nhân_viên giao bánh tiệm pizza phố Trần_Thái_Tông , Hà_Nội , trú tại quận Bắc_Từ_Liêm , lây từ \" bệnh_nhân 447 \" ( cũng là nhân_viên tiệm bánh , đi du_lịch Đà_Nẵng ) . </s>\n",
            "INFO:utils_ner:input_ids: 0 22 6207 54198 22 4 542 4 3952 126 4 8 650 574 1157 3568 17080 835 24661 4 120 4 1354 35 318 10866 4 8594 39 22 798 41045 22 20 32 8 650 3568 1157 4 57 388 623 19 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 7 19 19 2 19 0 19 19 19 3 12 12 4 13 13 13 19 4 19 19 19 4 13 19 19 19 19 19 7 19 19 19 19 3 12 12 19 19 19 4 19 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: dev-3\n",
            "INFO:utils_ner:tokens: <s> Trong số những người mà cô ấy đã tiếp_xúc với có nhân_viên M@@ GM . </s>\n",
            "INFO:utils_ner:input_ids: 0 92 100 21 18 64 106 241 14 1963 15 10 650 904 9702 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 19 19 19 19 19 19 19 19 19 19 6 -100 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: dev-4\n",
            "INFO:utils_ner:tokens: <s> Trong số hành_khách nhiễm có 3 người Việt là \" bệnh_nhân 17 \" Nguyễn_Hồng_@@ Nhung , \" bệnh_nhân 21 \" Nguyễn_Quang_@@ Thuấn và một nữ tiếp_viên hàng_không . </s>\n",
            "INFO:utils_ner:input_ids: 0 92 100 1442 2002 10 107 18 350 8 22 798 1120 22 7745 5323 4 22 798 1298 22 7631 17936 6 16 401 6596 2072 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 19 19 19 19 19 19 19 19 19 7 19 5 -100 19 19 19 7 19 5 -100 19 19 19 19 19 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: dev-5\n",
            "INFO:utils_ner:tokens: <s> Bệnh_viện đa_khoa Trung_ương Quảng_Nam công_bố khỏi bệnh và cho xuất_viện 9 bệnh_nhân , gồm bệnh_nhân 5@@ 98 ( 8 tuổi ) , bệnh_nhân 7@@ 74 ( 63 tuổi ) , bệnh_nhân 911 ( 79 tuổi ) , bệnh_nhân 432 ( 63 tuổi ) , bệnh_nhân 835 ( 26 tuổi ) , bệnh_nhân 7@@ 92 ( 25 tuổi ) , bệnh_nhân 463 ( 42 tuổi ) , bệnh_nhân 720 ( 30 tuổi ) và bệnh_nhân 7@@ 36 ( 39 tuổi ) . </s>\n",
            "INFO:utils_ner:input_ids: 0 1089 5079 736 1831 576 353 326 6 13 9720 426 798 4 479 798 1765 5859 20 358 126 19 4 798 1546 5007 20 3555 126 19 4 798 15244 20 4981 126 19 4 798 42604 20 3555 126 19 4 798 30142 20 1742 126 19 4 798 1546 4687 20 1058 126 19 4 798 46735 20 3121 126 19 4 798 15171 20 504 126 19 6 798 1546 2310 20 3202 126 19 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 6 15 15 15 19 19 19 19 19 19 19 19 19 19 19 7 -100 19 0 19 19 19 19 7 -100 19 0 19 19 19 19 7 19 0 19 19 19 19 7 19 0 19 19 19 19 7 19 0 19 19 19 19 7 -100 19 0 19 19 19 19 7 19 0 19 19 19 19 7 19 0 19 19 19 19 7 -100 19 0 19 19 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "model.safetensors:   6% 94.4M/1.48G [00:03<01:01, 22.5MB/s]INFO:utils_ner:Saving features into cached file /content/cached_dev_PhobertTokenizer_128\n",
            "model.safetensors:  48% 713M/1.48G [00:08<00:06, 127MB/s]/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:2183: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:2409] 2025-06-05 05:51:58,134 >> ***** Running training *****\n",
            "[INFO|trainer.py:2410] 2025-06-05 05:51:58,134 >>   Num examples = 5,029\n",
            "[INFO|trainer.py:2411] 2025-06-05 05:51:58,135 >>   Num Epochs = 1\n",
            "[INFO|trainer.py:2412] 2025-06-05 05:51:58,135 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:2415] 2025-06-05 05:51:58,135 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2416] 2025-06-05 05:51:58,135 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2417] 2025-06-05 05:51:58,135 >>   Total optimization steps = 315\n",
            "[INFO|trainer.py:2418] 2025-06-05 05:51:58,136 >>   Number of trainable parameters = 368,134,164\n",
            "[INFO|integration_utils.py:832] 2025-06-05 05:51:58,143 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "model.safetensors: 100% 1.48G/1.48G [00:16<00:00, 87.3MB/s]\n",
            "2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthangltkk54\u001b[0m (\u001b[33mthangltkk54-ptit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250605_055901-tgi4x14h\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/content/pho_bert_large/lr5e-5_bs16\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/thangltkk54-ptit/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/thangltkk54-ptit/huggingface/runs/tgi4x14h\u001b[0m\n",
            "100% 315/315 [06:19<00:00,  1.02it/s][INFO|trainer.py:3993] 2025-06-05 06:05:21,300 >> Saving model checkpoint to /content/pho_bert_large/lr5e-5_bs16/checkpoint-315\n",
            "[INFO|configuration_utils.py:424] 2025-06-05 06:05:21,302 >> Configuration saved in /content/pho_bert_large/lr5e-5_bs16/checkpoint-315/config.json\n",
            "[INFO|modeling_utils.py:3724] 2025-06-05 06:05:31,637 >> Model weights saved in /content/pho_bert_large/lr5e-5_bs16/checkpoint-315/model.safetensors\n",
            "[INFO|trainer.py:2676] 2025-06-05 06:05:47,250 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 829.1145, 'train_samples_per_second': 6.066, 'train_steps_per_second': 0.38, 'train_loss': 0.2507731361994668, 'epoch': 1.0}\n",
            "100% 315/315 [06:45<00:00,  1.29s/it]\n",
            "[INFO|trainer.py:3993] 2025-06-05 06:05:47,337 >> Saving model checkpoint to /content/pho_bert_large/lr5e-5_bs16\n",
            "[INFO|configuration_utils.py:424] 2025-06-05 06:05:47,339 >> Configuration saved in /content/pho_bert_large/lr5e-5_bs16/config.json\n",
            "[INFO|modeling_utils.py:3724] 2025-06-05 06:05:58,011 >> Model weights saved in /content/pho_bert_large/lr5e-5_bs16/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2525] 2025-06-05 06:05:58,014 >> tokenizer config file saved in /content/pho_bert_large/lr5e-5_bs16/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2534] 2025-06-05 06:05:58,014 >> Special tokens file saved in /content/pho_bert_large/lr5e-5_bs16/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2585] 2025-06-05 06:05:58,015 >> added tokens file saved in /content/pho_bert_large/lr5e-5_bs16/added_tokens.json\n",
            "INFO:__main__:*** Evaluate ***\n",
            "[INFO|trainer.py:4327] 2025-06-05 06:05:58,019 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:4329] 2025-06-05 06:05:58,019 >>   Num examples = 2003\n",
            "[INFO|trainer.py:4332] 2025-06-05 06:05:58,020 >>   Batch size = 16\n",
            "100% 126/126 [00:50<00:00,  2.49it/s]\n",
            "INFO:__main__:***** Eval results *****\n",
            "INFO:__main__:  eval_loss = 0.07267877459526062\n",
            "INFO:__main__:  eval_accuracy_score = 0.9821260416111437\n",
            "INFO:__main__:  eval_precision = 0.929476296199556\n",
            "INFO:__main__:  eval_recall = 0.9514705882352941\n",
            "INFO:__main__:  eval_f1 = 0.9403448503666512\n",
            "INFO:__main__:  eval_runtime = 51.1265\n",
            "INFO:__main__:  eval_samples_per_second = 39.177\n",
            "INFO:__main__:  eval_steps_per_second = 2.464\n",
            "INFO:__main__:  epoch = 1.0\n",
            "INFO:utils_ner:Creating features from dataset file at /content\n",
            "INFO:utils_ner:Writing example 0 of 3008\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: test-1\n",
            "INFO:utils_ner:tokens: <s> Từ 24 - 7 đến 31 - 7 , bệnh_nhân được mẹ là bà H.@@ T.P ( 47 tuổi ) đón về nhà ở phường Phước_Hoà ( bằng xe_máy ) , không đi đâu chỉ ra Tạ@@ p_@@ hoá Phượng , chợ Vườn_@@ Lài , phường An_Sơn cùng mẹ bán tạp_hoá ở đây . </s>\n",
            "INFO:utils_ner:input_ids: 0 404 1173 31 317 30 2330 31 317 4 798 11 269 8 155 2719 38033 20 3509 126 19 1101 28 69 25 557 33820 20 121 981 19 4 17 57 602 66 40 22862 4680 1738 4475 4 932 15796 28543 4 557 35173 81 269 170 11616 25 97 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 1 11 11 19 1 11 11 19 19 19 19 19 19 5 -100 19 0 19 19 19 19 19 19 4 13 19 19 19 19 19 19 19 19 19 19 4 -100 -100 13 19 4 13 -100 19 4 13 19 19 3 12 19 19 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: test-2\n",
            "INFO:utils_ner:tokens: <s> Bác_sĩ Trần_Thanh_@@ Linh , từ Bệnh_viện Chợ_Rẫy chi_viện phụ_trách đơn_nguyên hồi_sức tích_cực , cho biết \" bệnh_nhân 416 \" vẫn đang duy_trì E@@ CM@@ O , thở máy , hiện xơ phổi rất nhiều . </s>\n",
            "INFO:utils_ner:input_ids: 0 3608 10701 1757 4 39 1089 9675 18393 2433 28411 11916 727 4 13 55 22 798 39340 22 74 52 1040 1337 13264 3086 4 2194 558 4 380 4737 3154 59 36 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 -100 19 19 6 15 19 19 19 19 19 19 19 19 19 19 7 19 19 19 19 19 -100 -100 19 19 19 19 19 8 17 17 17 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: test-3\n",
            "INFO:utils_ner:tokens: <s> Theo đó , Sở Y_tế Bình_Thuận cho biết sau khi xác_định bệnh_nhân số 34 ( nữ_giới 51 tuổi , từ Mỹ về Việt_Nam ngày 29 - 2 có quá_cảnh Qatar ) , Trung_tâm Kiểm_soát bệnh_tật Bình_Thuận đã điều_tra dịch_tễ , khoanh vùng , khử khuẩn , tiến_hành cách_ly người liên_quan đến ca bệnh số 34 . </s>\n",
            "INFO:utils_ner:input_ids: 0 79 37 4 406 1059 3347 13 55 53 26 600 798 100 2682 20 7866 3601 126 4 39 93 28 56 43 1841 31 76 10 15687 4382 19 4 664 8380 4349 3347 14 377 21922 4 8483 275 4 8862 7172 4 486 8677 18 314 30 853 326 100 2682 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 19 6 15 15 19 19 19 19 19 19 19 7 19 2 0 19 19 19 4 19 4 19 1 11 11 19 19 4 19 19 6 15 15 15 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 7 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: test-4\n",
            "INFO:utils_ner:tokens: <s> Bệnh_nhân 218 : nữ , 43 tuổi , quốc_tịch Việt_Nam , địa_chỉ tại Phú_@@ Xá , Thái_Nguyên , về nước trên chuyến bay SU@@ 290 ( số ghế 46 G ) ngày 25 - 3 , sau nhập_cảnh được cách_ly tập_trung tại Đại_học FPT ở Láng - Hoà_Lạc ( Hà_Nội ) . Từ 31 - 3 bệnh_nhân được cách_ly , điều_trị tại Bệnh_viện Bệnh nhiệt_đới trung_ương cơ_sở 2 . </s>\n",
            "INFO:utils_ner:input_ids: 0 6207 22677 27 401 4 3415 126 4 5267 56 4 2065 35 4554 7803 4 3171 4 28 58 34 550 620 26257 15567 20 100 1435 3283 2787 19 43 1058 31 107 4 53 7547 11 8677 489 35 850 4062 25 12134 31 12132 20 120 19 5 404 2330 31 107 798 11 8677 4 782 35 1089 4577 5167 3205 341 76 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 7 19 2 19 0 19 19 19 19 19 19 19 4 -100 19 4 19 19 19 19 19 19 9 -100 19 19 19 19 19 19 19 1 11 11 19 19 19 19 19 19 19 4 13 19 4 19 4 19 4 19 19 19 1 11 11 19 19 19 19 19 19 4 13 13 13 13 13 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:*** Example ***\n",
            "INFO:utils_ner:guid: test-5\n",
            "INFO:utils_ner:tokens: <s> Ông cùng 4 người khác hôm 4/3 từ Malaysia về sân_bay Tân_Sơn_Nhất trên chuyến bay VJ 8@@ 26 . </s>\n",
            "INFO:utils_ner:input_ids: 0 168 81 163 18 85 654 21122 39 1396 28 1281 5211 34 550 620 36114 1556 1742 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:utils_ner:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:utils_ner:label_ids: -100 19 19 19 19 19 19 1 19 4 19 4 13 19 19 19 9 18 -100 19 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "INFO:utils_ner:Saving features into cached file /content/cached_test_PhobertTokenizer_128\n",
            "[INFO|trainer.py:4327] 2025-06-05 06:06:50,709 >> \n",
            "***** Running Prediction *****\n",
            "[INFO|trainer.py:4329] 2025-06-05 06:06:50,709 >>   Num examples = 3008\n",
            "[INFO|trainer.py:4332] 2025-06-05 06:06:50,709 >>   Batch size = 16\n",
            "100% 188/188 [01:15<00:00,  2.50it/s]\n",
            "INFO:__main__:  test_loss = 0.08768285810947418\n",
            "INFO:__main__:  test_accuracy_score = 0.977964004762016\n",
            "INFO:__main__:  test_precision = 0.916375727348296\n",
            "INFO:__main__:  test_recall = 0.9393319700068167\n",
            "INFO:__main__:  test_f1 = 0.927711857275099\n",
            "INFO:__main__:  test_runtime = 75.7393\n",
            "INFO:__main__:  test_samples_per_second = 39.715\n",
            "INFO:__main__:  test_steps_per_second = 2.482\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33m/content/pho_bert_large/lr5e-5_bs16\u001b[0m at: \u001b[34mhttps://wandb.ai/thangltkk54-ptit/huggingface/runs/tgi4x14h\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250605_055901-tgi4x14h/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MyUtils.analyze_sentence_lengths('/content/pho_bert_large/lr5e-5_bs16/test_predictions.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4wTwkuIGzBI",
        "outputId": "317bcf55-0b40-474f-f3dd-1be54b407d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tổng số câu: 3008\n"
          ]
        }
      ]
    }
  ]
}